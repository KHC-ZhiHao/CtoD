{
  "version": 3,
  "sources": ["../lib/plugins/index.ts", "../lib/core/plugin.ts", "../lib/plugins/retry.ts", "../lib/plugins/print-log.ts", "../lib/plugins/limiter.ts", "../lib/plugins/role.ts", "../lib/templates.ts", "../lib/utils/chinese-conv.ts", "../lib/core/parser.ts", "../lib/broker/chat.ts", "../lib/utils/validate.ts", "../lib/utils/error.ts", "../lib/core/translator.ts", "../lib/ctod.ts", "../lib/utils/json.ts", "../lib/service/openai/index.ts", "../lib/service/openai/vision.ts", "../lib/service/openai/chat.ts", "../lib/service/openai/images-generation.ts", "../lib/service/llama-cpp/index.ts", "../lib/service/llama-cpp/completion.ts", "../lib/service/google/chat.ts", "../lib/service/google/images-generation.ts", "../lib/service/google/index.ts", "../lib/service/anthropic/chat.ts", "../lib/service/anthropic/index.ts", "../lib/service/x/index.ts", "../lib/service/x/chat.ts", "../lib/service/x/images-generation.ts"],
  "sourcesContent": ["import Retry from './retry.js'\nimport PrintLog from './print-log.js'\nimport Limiter from './limiter.js'\nimport Role from './role.js'\n\n/**\n * @zh \u4E00\u500B\u57FA\u65BC\u5370\u51FA log \u7684 plugin\u3002\n * @en A plugin based on printing log.\n */\n\nexport const PrintLogPlugin = PrintLog\n\n/**\n * @zh \u7576\u89E3\u6790\u5931\u6557\u6642\uFF0C\u6703\u81EA\u52D5\u91CD\u8A66\u7684\u5C0D\u8A71\u3002\n * @en A conversation that will automatically retry when parsing fails.\n */\n\nexport const RetryPlugin = Retry\n\n/**\n * @zh \u9650\u5236\u4F7F\u7528\u6D41\u91CF\uFF0C\u9019\u500B plugin \u53EF\u4EE5\u6709\u6548\u8B93\u6240\u6709\u5C0D\u8A71\u4E0D\u6703\u518D\u9650\u5236\u5167\u540C\u6642\u767C\u9001\uFF0C\u53EF\u7528\u65BC\u5728\u958B\u767C\u904E\u7A0B\u4E2D\u906D\u9047\u4F3A\u670D\u5668\u56E0\u983B\u7387\u904E\u9AD8\u800C\u963B\u64CB\u8ACB\u6C42\u3002\n * @en Limit the use of traffic. This plugin can effectively prevent all conversations from being sent at the same time within the limit, and can be used when the server blocks requests due to high frequency during development.\n */\n\nexport const LimiterPlugin = Limiter.plugin\n\n/**\n * @zh \u6392\u7A0B\u7CFB\u7D71\u5C07\u5168\u57DF\u8A17\u7BA1\uFF0C\u6709\u4EC0\u9EBC\u5FC5\u8981\u8A2D\u5B9A\u53EF\u4EE5\u4F86\u66F4\u52D5\u5B83\u7684\u72C0\u614B\uFF0C\u4F8B\u5982\uFF1A\u95DC\u9589\u6392\u7A0B\u3002\n * @en The scheduling system will be globally hosted. What is necessary to set can come to change its status, for example: close the schedule.\n */\nexport const LimiterPluginGlobState = Limiter\n\n/**\n * @zh \u8A2D\u5B9A\u89D2\u8272\u626E\u6F14\u3002\n * @en Set role play.\n */\n\nexport const RolePlugin = Role\n", "import { Translator } from './translator.js'\nimport { ChatBrokerHooks } from '../broker/chat.js'\nimport { Log, Hook, Event } from 'power-helper'\nimport { ValidateCallback, ValidateCallbackOutputs } from '../utils/validate.js'\n\ntype BrokerHooks = ChatBrokerHooks<any, any, any, any>\ntype BrokerPluginParams<\n    T extends ValidateCallback<any>,\n    R extends ValidateCallback<any>\n> = {\n    name: string\n    params: T\n    receiveData: R\n    onInstall: (context: {\n        log: Log\n        params: ValidateCallbackOutputs<T>\n        attach: Hook<BrokerHooks>['attach']\n        attachAfter: Hook<BrokerHooks>['attachAfter']\n        translator: Translator<any, any>\n        receive: (callback: (params: {\n            id: string\n            data: ValidateCallbackOutputs<R>\n        }) => void) => void\n    }) => void\n}\n\nexport class ChatBrokerPlugin<\n    T extends ValidateCallback<any>,\n    R extends ValidateCallback<any>\n> {\n    _event = new Event()\n    _params: BrokerPluginParams<T, R>\n    constructor(params: BrokerPluginParams<T, R>) {\n        this._params = params\n    }\n\n    use(params: ValidateCallbackOutputs<T>) {\n        return {\n            instance: this as any,\n            params,\n            send: (data: ValidateCallbackOutputs<R>) => { this._event.emit('receive', data) },\n            receive: (callback: any) => { this._event.on('receive', callback) },\n            __receiveData: null as unknown as ValidateCallbackOutputs<R>\n        }\n    }\n}\n", "import { ChatBrokerPlugin } from '../core/plugin.js'\n\nexport default new ChatBrokerPlugin({\n    name: 'retry',\n    params: z => {\n        return {\n            retry: z.number().default(1),\n            printWarn: z.boolean().default(true)\n        }\n    },\n    receiveData: () => {\n        return {}\n    },\n    onInstall({ log, attach, params }) {\n        attach('parseFailed', async({ count, retry, messages, changeMessages }) => {\n            if (count <= params.retry) {\n                if (params.printWarn) {\n                    log.print(`Is Failed, Retry ${count} times.`)\n                }\n                changeMessages(messages)\n                retry()\n            }\n        })\n    }\n})\n", "import { ChatBrokerPlugin } from '../core/plugin.js'\n\nexport default new ChatBrokerPlugin({\n    name: 'print-log',\n    params: z => {\n        return {\n            detail: z.boolean().default(false)\n        }\n    },\n    receiveData: () => {\n        return {}\n    },\n    onInstall({ params, log, attach }) {\n        attach('talkBefore', async({ lastUserMessage, messages }) => {\n            log.print('Send:', { color: 'green' })\n            if (params.detail) {\n                log.print('\\n' + JSON.stringify(messages, null, 4))\n            } else {\n                log.print('\\n' + lastUserMessage)\n            }\n        })\n        attach('talkAfter', async({ parseText }) => {\n            log.print('Receive:', { color: 'cyan' })\n            log.print('\\n' + parseText)\n        })\n        attach('succeeded', async({ output }) => {\n            log.print('Output:', { color: 'yellow' })\n            try {\n                log.print('\\n' + JSON.stringify(output, null, 4))\n            } catch (error) {\n                log.print('\\n' + output)\n            }\n        })\n    }\n})\n", "import { ChatBrokerPlugin } from '../core/plugin.js'\nimport { Event, flow, Schedule } from 'power-helper'\n\ntype Events = {\n    run: {\n        id: string\n    }\n    waitTimeChange: {\n        waitTime: number\n    }\n}\n\nconst config = {\n    limit: 3,\n    interval: 60000,\n}\n\nconst state = {\n    event: new Event<Events>(),\n    schedule: null as Schedule | null,\n    waitTimes: [] as number[],\n    waitQueue: [] as string[]\n}\n\nexport default {\n    /**\n     * @zh \u4F60\u53EF\u4EE5\u76E3\u807D\u4E00\u4E9B\u4E8B\u4EF6\u884C\u70BA\uFF0C\u4F8B\u5982\u9084\u9700\u8981\u7B49\u5F85\u591A\u5C11\u6642\u9593\u3002\n     * @en You can listen for some event behaviors, such as how long you still need to wait.\n     */\n\n    event: state.event,\n\n    /**\n     * @zh \u9810\u8A2D\u662F\u6BCF\u5206\u9418\u9650\u52363\u6B21\uFF0C\u4F60\u53EF\u4EE5\u5728\u8A2D\u5B9A\u4E2D\u6539\u8B8A\u9650\u5236\u6D41\u91CF\u3002\n     * @en By default, the limit is 3 times per minute, and you can change the limit flow in the settings.\n     */\n\n    config,\n\n    /**\n     * @zh \u7531\u65BC\u6392\u7A0B\u6703\u5728\u80CC\u666F\u6301\u7E8C\u5012\u6578\uFF0C\u5982\u679C\u6709\u95DC\u9589\u7A0B\u5F0F\u7684\u9700\u6C42\uFF0C\u9700\u8981\u624B\u52D5\u9032\u884C\u79FB\u9664\u3002\n     * @en Since the schedule will continue to count down in the background, if there is a need to close the program, you need to manually remove it.\n     */\n\n    closeSchedule: () => {\n        if (state.schedule) {\n            state.schedule.close()\n            state.schedule = null\n        }\n    },\n\n    /**\n     * @zh Plugin \u7684\u63A5\u53E3\n     * @en Plugin interface\n     */\n\n    plugin: new ChatBrokerPlugin({\n        name: 'limiter',\n        params: () => {\n            return {}\n        },\n        receiveData: () => {\n            return {}\n        },\n        onInstall({ attach }) {\n            if (state.schedule == null) {\n                state.schedule = new Schedule()\n                state.schedule.add('calc queue', 1000, async() => {\n                    const now = Date.now()\n                    state.waitTimes = state.waitTimes.filter(time => {\n                        return now - time < config.interval\n                    })\n                    if (state.waitTimes.length !== config.limit) {\n                        let nextId = state.waitQueue.shift()\n                        if (nextId) {\n                            state.waitTimes.push(Date.now())\n                            state.event.emit('run', {\n                                id: nextId\n                            })\n                        }\n                    } else if (state.waitTimes[0]) {\n                        state.event.emit('waitTimeChange', {\n                            waitTime: Math.floor(60 - (now - state.waitTimes[0]) / 1000)\n                        })\n                    }\n                })\n                state.schedule.play()\n            }\n            attach('talkBefore', async() => {\n                const uid = flow.createUuid()\n                state.waitQueue.push(uid)\n                return new Promise(resolve => {\n                    state.event.on('run', ({ id }, { off }) => {\n                        if (id === uid) {\n                            off()\n                            resolve()\n                        }\n                    })\n                })\n            })\n        }\n    })\n}\n", "import { ChatBrokerPlugin } from '../core/plugin.js'\n\nexport default new ChatBrokerPlugin({\n    name: 'role',\n    params: z => {\n        return {\n            role: z.string()\n        }\n    },\n    receiveData: () => {\n        return {}\n    },\n    onInstall({ attach, params }) {\n        attach('start', async({ messages, changeMessages }) => {\n            changeMessages([\n                {\n                    role: 'user',\n                    content: `\u4F60\u73FE\u5728\u662F${params.role}\u3002`\n                },\n                {\n                    role: 'assistant',\n                    content: `\u6C92\u554F\u984C\uFF0C\u6211\u73FE\u5728\u662F${params.role}\uFF0C\u6709\u4EC0\u9EBC\u53EF\u4EE5\u5E6B\u4F60\u7684\u55CE\uFF1F`\n                },\n                ...messages\n            ])\n        })\n    }\n})\n", "import Handlebars from 'handlebars'\nimport { record } from 'power-helper'\n\ntype JsonResponseFormat = {\n    desc: string\n    example: any\n}\n\n/**\n * @zh \u5354\u52A9\u4F7F\u7528\u8005\u5C07\u683C\u5F0F\u9700\u6C42\u8F49\u6210\u8AD6\u6558\u8A9E\u53E5\u3002\n * @en Assist the user in converting the formatting requirements into declarative sentences.\n */\n\nexport const requireJsonResponse = (question: string | string[], format: Record<string, JsonResponseFormat>) => {\n    return [\n        ...(Array.isArray(question) ? question : [question]),\n        'Please respond using the following JSON format and minify the JSON without including any explanation: ',\n        '{',\n        Object.entries(format).map(([key, value]) => {\n            return [\n                `/* ${value.desc} */`,\n                `\"${key}\": ${JSON.stringify(value.example)}`,\n            ].join('\\n')\n        }).join(',\\n'),\n        '}'\n    ].join('\\n')\n}\n\n/**\n * @zh \u5354\u52A9\u4F7F\u7528\u8005\u5C07\u683C\u5F0F\u9700\u6C42\u8F49\u6210\u8AD6\u6558\u8A9E\u53E5\uFF0C\u652F\u63F4 Handlebars\u3002\n * @en Assist the user in converting the formatting requirements into declarative sentences, support Handlebars.\n */\n\nexport const requireJsonResponseWithHandlebars = (\n    value: Record<string, any>,\n    question: string | string[],\n    format: Record<string, JsonResponseFormat>\n) => {\n    const handlebars = Handlebars.create()\n\n    handlebars.registerHelper('DATA', function(this: any, value) {\n        return JSON.stringify(value)\n    })\n\n    handlebars.registerHelper('ENV', function(this: any, value) {\n        return this.__envs && value ? this.__envs[value] : ''\n    })\n\n    handlebars.registerHelper('INPUT', function(this: any) {\n        return JSON.stringify(record.omit(this, ['__envs']))\n    })\n\n    handlebars.registerHelper('JOIN', function(this: any, value) {\n        return Array.isArray(value) ? value.join() : JSON.stringify(value)\n    })\n\n    return handlebars.compile(requireJsonResponse(question, format))(value)\n}\n\n/**\n * @zh \u5354\u52A9\u4F7F\u7528\u8005\u5C07\u683C\u5F0F\u9700\u6C42\u8F49\u6210\u8AD6\u6558\u8A9E\u53E5\uFF0C\u4E26\u652F\u63F4 Json Schema\u3002\n * @en Assist the user in converting the formatting requirements into declarative sentences, and support Json Schema.\n */\n\nexport const requireJsonResponseWithJsonSchema = (question: string | string[], format: Record<string, any>) => {\n    return [\n        ...(Array.isArray(question) ? question : [question]),\n        'Please provide JSON data according to the following JSON Schema format:',\n        JSON.stringify(format)\n    ].join('\\n')\n}\n", "import { Converter } from 'opencc-js'\n\n/**\n * @zh \u7E41\u4F53\u8F6C\u7B80\u4F53\n * @en Traditional to Simplified\n*/\nexport const t2s = (text: string) => {\n    const converter = Converter({\n        from: 'tw',\n        to: 'cn'\n    })\n    return converter(text)\n}\n\n/**\n * @zh \u7B80\u4F53\u8F6C\u7E41\u4F53\n * @en Simplified to Traditional\n */\nexport const s2t = (text: string) => {\n    const converter = Converter({\n        from: 'cn',\n        to: 'tw'\n    })\n    return converter(text)\n}\n", "import JSON5 from 'json5'\n\ntype TextParserParams = {\n    /**\n     * @zh \u89E3\u8B80\u5668\u540D\u5B57\u3002\n     * @en The name of the parser.\n     */\n    name: string\n    /**\n     * @zh \u89E3\u8B80\u6587\u672C\u3002\n     * @en Read the text.\n     */\n    handler: (text: string) => Promise<any>\n}\n\nexport class TextParser {\n    private params: TextParserParams\n\n    /**\n     * @zh \u76E1\u53EF\u80FD\u5C07\u6587\u5B57\u5167\u7684 json \u89E3\u8B80\u51FA\u4F86\u3002\n     * @en Try to read the json in the text as much as possible.\n     */\n\n    static JsonMessage() {\n        return new TextParser({\n            name: 'JsonMessage',\n            handler: async (text) => {\n                try {\n                    const result = JSON.parse(text)\n                    return result\n                } catch (error) {\n                    const jsonRegex = /{(?:[^{}]|(?:{[^{}]*}))*}/\n                    const matchedText = text.match(jsonRegex)?.[0] || ''\n                    return JSON5.parse(matchedText)\n                }\n            }\n        })\n    }\n\n    constructor(params: TextParserParams) {\n        this.params = params\n    }\n\n    /**\n     * @zh \u89E3\u8B80\u5668\u540D\u5B57\u3002\n     * @en The name of the parser.\n     */\n\n    get name() {\n        return this.params.name\n    }\n\n    /**\n     * @zh \u89E3\u8B80\u6587\u672C\u3002\n     * @en Read the text.\n     */\n\n    async read(text: string) {\n        const result = await this.params.handler(text)\n        return result\n    }\n}\n", "import { TextParser } from '../core/parser.js'\nimport { ChatBrokerPlugin } from '../core/plugin.js'\nimport { Event, flow, Hook, Log } from 'power-helper'\nimport { Translator, TranslatorParams } from '../core/translator.js'\nimport { ValidateCallback, ValidateCallbackOutputs, validateToJsonSchema } from '../utils/validate.js'\nimport { ParserError } from '../utils/error.js'\nimport { z } from 'zod'\n\nexport type Message = {\n    role: 'system' | 'user' | 'assistant' | (string & Record<string, unknown>)\n    name?: string\n    content: string\n}\n\nexport type ChatBrokerHooks<\n    S extends ValidateCallback<any>,\n    O extends ValidateCallback<any>,\n    P extends ChatBrokerPlugin<any, any>,\n    PS extends Record<string, ReturnType<P['use']>>\n> = {\n\n    /**\n     * @zh \u7B2C\u4E00\u6B21\u804A\u5929\u7684\u6642\u5019\u89F8\u767C\n     * @en Triggered when chatting for the first time\n     */\n\n    start: {\n        id: string\n        data: ValidateCallbackOutputs<S>\n        metadata: Map<string, any>\n        plugins: {\n            [K in keyof PS]: {\n                send: (data: PS[K]['__receiveData']) => void\n            }\n        }\n        schema: {\n            input?: S\n            output: O\n        }\n        messages: Message[]\n        setPreMessages: (messages: (Omit<Message, 'content'> & { content: string | string[] })[]) => void\n        changeMessages: (messages: Message[]) => void\n        changeOutputSchema: (output: O) => void\n    }\n\n    /**\n     * @zh \u767C\u9001\u804A\u5929\u8A0A\u606F\u7D66\u6A5F\u5668\u4EBA\u524D\u89F8\u767C\n     * @en Triggered before sending chat message to bot\n     */\n\n    talkBefore: {\n        id: string\n        data: ValidateCallbackOutputs<S>\n        messages: Message[]\n        metadata: Map<string, any>\n        lastUserMessage: string\n    }\n\n    /**\n     * @zh \u7576\u804A\u5929\u6A5F\u5668\u4EBA\u56DE\u50B3\u8CC7\u6599\u7684\u6642\u5019\u89F8\u767C\n     * @en Triggered when the chatbot returns data\n     */\n\n    talkAfter: {\n        id: string\n        data: ValidateCallbackOutputs<S>\n        response: any\n        messages: Message[]\n        parseText: string\n        metadata: Map<string, any>\n        lastUserMessage: string\n        /**\n         * @zh \u5BA3\u544A\u89E3\u6790\u5931\u6557\n         * @en Declare parsing failure\n         */\n        parseFail: (error: any) => void\n        changeParseText: (text: string) => void\n    }\n\n    /**\n     * @zh \u7576\u56DE\u50B3\u8CC7\u6599\u7B26\u5408\u898F\u683C\u6642\u89F8\u767C\n     * @en Triggered when the returned data meets the specifications\n     */\n\n    succeeded: {\n        id: string\n        metadata: Map<string, any>\n        output: ValidateCallbackOutputs<O>\n    }\n\n    /**\n     * @zh \u7576\u56DE\u50B3\u8CC7\u6599\u4E0D\u7B26\u5408\u898F\u683C\uFF0C\u6216\u662F\u89E3\u6790\u932F\u8AA4\u6642\u89F8\u767C\n     * @en Triggered when the returned data does not meet the specifications or parsing errors\n     */\n\n    parseFailed: {\n        id: string\n        error: any\n        retry: () => void\n        count: number\n        response: any\n        metadata: Map<string, any>\n        parserFails: { name: string, error: any }[]\n        messages: Message[]\n        lastUserMessage: string\n        changeMessages: (messages: Message[]) => void\n    }\n\n    /**\n     * @zh \u4E0D\u8AD6\u6210\u529F\u5931\u6557\uFF0C\u57F7\u884C\u7D50\u675F\u7684\u6642\u5019\u6703\u57F7\u884C\u3002\n     * @en It will be executed when the execution is completed, regardless of success or failure.\n     */\n\n    done: {\n        id: string\n        metadata: Map<string, any>\n    }\n}\n\nexport type RequestContext = {\n    id: string\n    count: number\n    isRetry: boolean\n    metadata: Map<string, any>\n    abortController: AbortController\n    onCancel: (cb: () => void) => void\n    schema: {\n        input: any\n        output: any\n    }\n}\n\nexport type Params<\n    S extends ValidateCallback<any>,\n    O extends ValidateCallback<any>,\n    C extends Record<string, any>,\n    P extends ChatBrokerPlugin<any, any>,\n    PS extends Record<string, ReturnType<P['use']>>\n> = Omit<TranslatorParams<S, O>, 'parsers'> & {\n    name?: string\n    plugins?: PS | (() => PS)\n    request: (messages: Message[], context: RequestContext) => Promise<string>\n    install?: (context: {\n        log: Log\n        attach: Hook<C>['attach']\n        attachAfter: Hook<C>['attachAfter']\n        translator: Translator<S, O>\n    }) => void\n}\n\nexport class ChatBroker<\n    S extends ValidateCallback<any>,\n    O extends ValidateCallback<any>,\n    P extends ChatBrokerPlugin<any, any>,\n    PS extends Record<string, ReturnType<P['use']>>,\n    C extends ChatBrokerHooks<S, O, P, PS> = ChatBrokerHooks<S, O, P, PS>\n> {\n    protected __hookType!: C\n    protected log: Log\n    protected hook = new Hook<C>()\n    protected params: Params<S, O, C, P, PS>\n    protected plugins = {} as PS\n    protected installed = false\n    protected translator: Translator<S, O>\n    protected event = new Event<{\n        cancel: {\n            requestId: string\n        }\n        cancelAll: any\n    }>()\n\n    constructor(params: Params<S, O, C, P, PS>) {\n        this.log = new Log(params.name ?? 'no name')\n        this.params = params\n        this.translator = new Translator({\n            ...params,\n            parsers: [\n                TextParser.JsonMessage()\n            ]\n        })\n    }\n\n    protected _install(): any {\n        if (this.installed === false) {\n            this.installed = true\n            const context = {\n                log: this.log,\n                attach: this.hook.attach.bind(this.hook),\n                attachAfter: this.hook.attachAfter.bind(this.hook),\n                translator: this.translator\n            }\n            if (this.params.plugins) {\n                this.plugins = typeof this.params.plugins === 'function' ? this.params.plugins() : this.params.plugins\n                for (let key in this.plugins) {\n                    this.plugins[key].instance._params.onInstall({\n                        ...context,\n                        params: this.plugins[key].params,\n                        receive: this.plugins[key].receive\n                    })\n                }\n            }\n            this.params.install?.(context)\n        }\n    }\n\n    async cancel(requestId?: string) {\n        if (requestId) {\n            this.event.emit('cancel', {\n                requestId\n            })\n        } else {\n            this.event.emit('cancelAll', {})\n        }\n    }\n\n    requestWithId<T extends Translator<S, O>>(data: T['__schemeType']): {\n        id: string\n        request: Promise<T['__outputType']>\n    } {\n        this._install()\n        let id = flow.createUuid()\n        let waitCancel = null as (() => void) | null\n        let isCancel = false\n        let isSending = false\n        let abortController = new AbortController()\n\n        // =================\n        //\n        // event\n        //\n\n        const listeners = [\n            this.event.on('cancel', ({ requestId }) => {\n                if (requestId === id) {\n                    cancelTrigger()\n                }\n            }),\n            this.event.on('cancelAll', () => {\n                cancelTrigger()\n            })\n        ]\n        const eventOff = () => listeners.forEach(e => e.off())\n        const cancelTrigger = () => {\n            if (isCancel === false) {\n                if (isSending && waitCancel) {\n                    waitCancel()\n                }\n                abortController.abort()\n                isCancel = true\n                eventOff()\n            }\n        }\n        const onCancel = (cb: () => void) => {\n            waitCancel = () => {\n                cb()\n            }\n        }\n\n        // =================\n        //\n        // main\n        //\n\n        let request = async() => {\n            let schema = this.translator.getValidate()\n            let output: any = null\n            let plugins = {} as any\n            let metadata = new Map()\n            let question = await this.translator.compile(data, {\n                schema\n            })\n            let preMessages: Message[] = []\n            let messages: Message[] = []\n            if (question.prompt) {\n                messages.push({\n                    role: 'user',\n                    content: question.prompt\n                })\n            }\n            for (let key in this.plugins) {\n                plugins[key] = {\n                    send: (data: any) => this.plugins[key].send({\n                        id,\n                        data\n                    })\n                }\n            }\n            await this.hook.notify('start', {\n                id,\n                data,\n                schema,\n                plugins,\n                messages,\n                metadata,\n                setPreMessages: ms => {\n                    preMessages = ms.map(e => {\n                        return {\n                            ...e,\n                            content: Array.isArray(e.content) ? e.content.join('\\n') : e.content\n                        }\n                    })\n                },\n                changeMessages: ms => {\n                    messages = ms\n                },\n                changeOutputSchema: output => {\n                    this.translator.changeOutputSchema(output)\n                    schema = this.translator.getValidate()\n                }\n            })\n            messages = [\n                ...preMessages,\n                ...messages\n            ]\n            await flow.asyncWhile(async ({ count, doBreak }) => {\n                if (count >= 99) {\n                    return doBreak()\n                }\n                let response = ''\n                let parseText = ''\n                let retryFlag = false\n                let lastUserMessage = messages.filter(e => e.role === 'user').slice(-1)[0]?.content || ''\n                try {\n                    await this.hook.notify('talkBefore', {\n                        id,\n                        data,\n                        messages,\n                        metadata,\n                        lastUserMessage\n                    })\n                    const sender = this.params.request(messages, {\n                        id,\n                        count,\n                        schema,\n                        onCancel,\n                        metadata,\n                        abortController,\n                        isRetry: retryFlag\n                    })\n                    if (isCancel) {\n                        if (waitCancel) {\n                            waitCancel()\n                        }\n                        abortController.abort()\n                    } else {\n                        try {\n                            isSending = true\n                            response = await sender\n                            parseText = response\n                        } finally {\n                            isSending = false\n                        }\n                    }\n                    if (isCancel === false) {\n                        await this.hook.notify('talkAfter', {\n                            id,\n                            data,\n                            response,\n                            messages,\n                            parseText,\n                            metadata,\n                            lastUserMessage,\n                            parseFail: (error) => {\n                                throw new ParserError(error, [])\n                            },\n                            changeParseText: text => {\n                                parseText = text\n                            }\n                        })\n                        output = (await this.translator.parse(parseText)).output\n                        await this.hook.notify('succeeded', {\n                            id,\n                            output,\n                            metadata\n                        })\n                    }\n                    await this.hook.notify('done', {\n                        id,\n                        metadata\n                    })\n                    doBreak()\n                } catch (error: any) {\n                    // \u5982\u679C\u89E3\u6790\u932F\u8AA4\uFF0C\u53EF\u4EE5\u9078\u64C7\u662F\u5426\u91CD\u65B0\u89E3\u8B80\n                    if (error instanceof ParserError) {\n                        await this.hook.notify('parseFailed', {\n                            id,\n                            error: error.error,\n                            count,\n                            response,\n                            messages,\n                            metadata,\n                            lastUserMessage,\n                            parserFails: error.parserFails,\n                            retry: () => {\n                                retryFlag = true\n                            },\n                            changeMessages: ms => {\n                                messages = ms\n                            }\n                        })\n                        if (retryFlag === false) {\n                            await this.hook.notify('done', {\n                                id,\n                                metadata\n                            })\n                            throw error\n                        }\n                    } else {\n                        await this.hook.notify('done', {\n                            id,\n                            metadata\n                        })\n                        throw error\n                    }\n                }\n            })\n            return output\n        }\n        const send = async() => {\n            try {\n                const result = await request()\n                return result\n            } finally {\n                eventOff()\n            }\n        }\n        return {\n            id,\n            request: send()\n        }\n    }\n\n    /**\n     * @zh \u5C07\u8ACB\u6C42\u767C\u51FA\u81F3\u804A\u5929\u6A5F\u5668\u4EBA\u3002\n     * @en Send request to chatbot.\n     */\n\n    async request<T extends Translator<S, O>>(data: T['__schemeType']): Promise<T['__outputType']> {\n        const { request } = this.requestWithId(data)\n        const output = await request\n        return output\n    }\n\n    /**\n     * @zh \u53D6\u5F97\u9810\u5148\u8ACB\u6C42\u7684\u8CC7\u8A0A\uFF0C\u5305\u542B\u8F38\u51FA\u898F\u683C\u8207\u9810\u8A2D\u8A0A\u606F\uFF0C\u9019\u751F\u547D\u9031\u671F\u53EA\u6703\u57F7\u884C\u5230 start \u968E\u6BB5\u70BA\u6B62\uFF0C\u4E5F\u4E0D\u6703\u89F8\u767C plugin\u3002\n     * @en Get pre-request information, including output specifications and default messages. This life cycle will only execute up to the start stage and will not trigger plugins.\n     */\n\n    async getPreRequestInfo<T extends Translator<S, O>>(data: T['__schemeType']) {\n        this._install()\n        let id = flow.createUuid()\n        let schema = this.translator.getValidate()\n        let plugins = {} as any\n        let metadata = new Map()\n        let question = await this.translator.compile(data, {\n            schema\n        })\n        let preMessages: Message[] = []\n        let messages: Message[] = []\n        if (question.prompt) {\n            messages.push({\n                role: 'user',\n                content: question.prompt\n            })\n        }\n        await this.hook.notify('start', {\n            id,\n            data,\n            schema,\n            plugins,\n            messages,\n            metadata,\n            setPreMessages: ms => {\n                preMessages = ms.map(e => {\n                    return {\n                        ...e,\n                        content: Array.isArray(e.content) ? e.content.join('\\n') : e.content\n                    }\n                })\n            },\n            changeMessages: ms => {\n                messages = ms\n            },\n            changeOutputSchema: output => {\n                this.translator.changeOutputSchema(output)\n                schema = this.translator.getValidate()\n            }\n        })\n        const outputSchema = schema.output(z)\n        return {\n            outputSchema,\n            outputJsonSchema: validateToJsonSchema(() => schema.output(z) as any),\n            requestMessages: [\n                ...preMessages,\n                ...messages\n            ]\n        }\n    }\n}\n", "import { z, toJSONSchema } from 'zod'\n\nexport type ValidateCallback<T extends Record<string, z.ZodTypeAny>> = (_z: typeof z) => {\n    [K in keyof T]: T[K]\n}\n\nexport type ValidateCallbackOutputs<\n    T extends ValidateCallback<any>,\n    R = ReturnType<T>\n> = {\n    [K in keyof R]: R[K] extends z.ZodTypeAny ? z.infer<R[K]> : R[K]\n}\n\nexport function definedValidateSchema<T extends ValidateCallback<any>>(cb: T): T {\n    return cb\n}\n\nexport function validate<\n    T extends ValidateCallback<any>,\n    R = ReturnType<T>\n>(target: any, schemaCallback: T) {\n    return z.object(schemaCallback(z)).parse(target || {}) as {\n        [K in keyof R]: R[K] extends z.ZodTypeAny ? z.infer<R[K]> : R[K]\n    }\n}\n\nexport function validateToJsonSchema<T extends ValidateCallback<any>>(target: () => T) {\n    const schema = toJSONSchema(z.object(target()))\n    delete schema.$schema\n    return schema\n}\n", "type ParserFail = {\n    name: string\n    error: any\n}\n\nexport class ParserError {\n    isParserError = true\n    parserFails: ParserFail[] = []\n    error: any\n    constructor(error: any, parserFails: ParserFail[]) {\n        this.error = error\n        this.parserFails = parserFails\n    }\n}\n", "import { TextParser } from './parser.js'\nimport { validate, ValidateCallback, ValidateCallbackOutputs } from '../utils/validate.js'\nimport { ParserError } from '../utils/error.js'\n\nexport type TranslatorParams<\n    S extends ValidateCallback<any>,\n    O extends ValidateCallback<any>\n> = {\n    /**\n     * @zh \u8F38\u5165\u7684\u8CC7\u6599\u683C\u5F0F\u3002\n     * @en The input data format.\n     */\n    input?: S\n    /**\n     * @zh \u8F38\u51FA\u7684\u8CC7\u6599\u683C\u5F0F\u3002\n     * @en The output data format.\n     */\n    output: O\n    /**\n     * @zh \u8A3B\u518A\u89E3\u8B80\u6587\u5B57\u7684\u89E3\u6790\u5668\u3002\n     * @en Register the parser to interpret the text.\n     */\n    parsers: TextParser[]\n    /**\n     * @zh \u7D44\u5408\u8F38\u5165\u8CC7\u6599\u6210\u70BA\u63D0\u793A\u6587\u5B57\u3002\n     * @en Combine the input data into a prompt.\n     */\n    question?: (data: ValidateCallbackOutputs<S>, context: {\n        schema: {\n            input?: S\n            output: O\n        }\n    }) => Promise<string | string[]>\n}\n\nexport class Translator<\n    S extends ValidateCallback<any>,\n    O extends ValidateCallback<any>\n> {\n    private params: TranslatorParams<S, O>\n\n    constructor(params: TranslatorParams<S, O>) {\n        this.params = params\n    }\n\n    get __schemeType(): ValidateCallbackOutputs<S> {\n        return null as any\n    }\n\n    get __outputType(): ValidateCallbackOutputs<O> {\n        return null as any\n    }\n\n    /**\n     * @zh \u7D44\u5408\u8F38\u5165\u8CC7\u6599\u6210\u70BA\u63D0\u793A\u6587\u5B57\u3002\n     * @en Combine the input data into a prompt.\n     */\n\n    async compile(data: ValidateCallbackOutputs<S>, context: {\n        schema: {\n            input?: S\n            output: O\n        }\n    }) {\n        const scheme = this.params.input ? validate(data, this.params.input) : data\n        const prompt = this.params.question ? await this.params.question(scheme, context) : ''\n        return {\n            scheme,\n            prompt: Array.isArray(prompt) ? prompt.join('\\n') : prompt\n        }\n    }\n\n    getValidate() {\n        return {\n            input: this.params.input,\n            output: this.params.output\n        }\n    }\n\n    changeOutputSchema(schema: O) {\n        this.params.output = schema\n    }\n\n    /**\n     * @zh \u5C07\u6587\u5B57\u8F49\u63DB\u6210\u5E8F\u5217\u5316\u8CC7\u6599\u3002\n     * @en Convert text to serialized data.\n     */\n\n    async parse(text: string) {\n        let result: any = undefined\n        let parserName = ''\n        let parserFails: { name: string, error: any }[] = []\n        for (let parse of this.params.parsers) {\n            try {\n                result = await parse.read(text)\n                parserName = parse.name\n            } catch (error) {\n                result = undefined\n                parserFails.push({\n                    name: parse.name,\n                    error\n                })\n            }\n        }\n        try {\n            let output = validate(result, this.params.output)\n            return {\n                output,\n                parserName,\n                parserFails\n            }\n        } catch (error) {\n            throw new ParserError(error, parserFails)\n        }\n    }\n}\n", "import { ChatBroker, Message, Params as ChatBrokerParams, ChatBrokerHooks, RequestContext } from './broker/chat.js'\nimport { ChatBrokerPlugin } from './core/plugin.js'\nimport * as z from 'zod'\n\ntype IO = any\n\nexport class CtoD<\n    P extends ChatBrokerPlugin<IO, IO>,\n    PS extends Record<string, ReturnType<P['use']>>\n> {\n    params\n    constructor(params: {\n        request: (messages: Message[], context: RequestContext) => Promise<string>\n        plugins?: () => PS\n    }) {\n        this.params = params\n    }\n\n    createBrokerBuilder<I extends Record<string, any>>(params?: {\n        install?: ChatBrokerParams<() => I, IO, ChatBrokerHooks<() => I, IO, P, PS>, P, PS>['install']\n    }) {\n        return {\n            create: <O extends Record<string, z.ZodTypeAny>>(install: (context: {\n                id: string\n                zod: typeof z\n                data: I\n                plugins: {\n                    [K in keyof PS]: {\n                        send: (data: PS[K]['__receiveData']) => void\n                    }\n                }\n                setMessages: (messages: (Omit<Message, 'content'> & { content: string | string[] })[]) => void\n                metadata: Map<string, any>\n            }) => Promise<O>) => {\n                return new ChatBroker<\n                    () => I,\n                    () => O,\n                    P,\n                    PS,\n                    ChatBrokerHooks<() => I, () => O, P, PS>\n                >({\n                    output: () => ({} as any),\n                    install: (context) => {\n                        params?.install?.(context)\n                        context.attach('start', async({ id, plugins, data, metadata, changeMessages, changeOutputSchema }) => {\n                            const schema = await install({\n                                id,\n                                data: data as any,\n                                plugins,\n                                zod: z,\n                                setMessages: (messages) => {\n                                    changeMessages(messages.map(e => {\n                                        return {\n                                            role: e.role,\n                                            content: Array.isArray(e.content) ? e.content.join('\\n') : e.content\n                                        }\n                                    }))\n                                },\n                                metadata\n                            })\n                            changeOutputSchema(() => schema)\n                        })\n                    },\n                    plugins: this.params.plugins ? () => this.params.plugins!() : undefined,\n                    request: this.params.request\n                })\n            }\n        }\n    }\n}\n", "export const parseJSONStream = <T>(data: string): {\n    items: T[]\n    lastChunk: string\n} => {\n    const items: T[] = []\n    let buffer = ''\n    let depth = 0\n    let inString = false\n    let escapeNext = false\n    let objectStarted = false\n\n    for (let i = 0; i < data.length; i++) {\n        const char = data[i]\n\n        if (escapeNext) {\n            escapeNext = false\n            if (objectStarted) buffer += char\n            continue\n        }\n        if (char === '\\\\') {\n            escapeNext = true\n            if (objectStarted) buffer += char\n            continue\n        }\n        if (char === '\"') {\n            inString = !inString\n            if (objectStarted) buffer += char\n            continue\n        }\n        if (!inString) {\n            if (char === '{') {\n                if (depth === 0) {\n                    objectStarted = true\n                    buffer = '{'\n                } else {\n                    buffer += char\n                }\n                depth++\n            } else if (char === '}') {\n                depth--\n                buffer += char\n                if (depth === 0 && objectStarted) {\n                    const trimmed = buffer.trim()\n                    if (trimmed) {\n                        try {\n                            items.push(JSON.parse(trimmed))\n                        } catch {\n                            // \u89E3\u6790\u5931\u6557\uFF0C\u5FFD\u7565\n                        }\n                    }\n                    buffer = ''\n                    objectStarted = false\n                }\n            } else if (objectStarted) {\n                buffer += char\n            }\n        } else if (objectStarted) {\n            buffer += char\n        }\n    }\n\n    return {\n        items,\n        lastChunk: objectStarted ? buffer.trim() : ''\n    }\n}\n", "import axios from 'axios'\nimport { OpenAIVision } from './vision.js'\nimport { OpenAIChat, Config } from './chat.js'\nimport { OpenAIImagesGeneration } from './images-generation.js'\nimport { validateToJsonSchema } from '../../utils/validate.js'\n\nexport class OpenAICtodService {\n    _axios = axios.create()\n    _apiKey = ''\n    _baseUrl = 'https://api.openai.com'\n\n    static createChatRequest(\n        apiKey: string | (() => Promise<string>),\n        config: Partial<Config> | (() => Promise<Partial<Config>>) = {},\n        options?: {\n            axios?: any\n            baseUrl?: string\n        }\n    ) {\n        return async(messages: any[], { abortController }: any) => {\n            const openai = new OpenAICtodService(typeof apiKey === 'string' ? apiKey : await apiKey())\n            const chat = openai.createChat()\n            if (options) {\n                if (options.axios) {\n                    openai.setAxios(options.axios)\n                }\n                if (options.baseUrl) {\n                    openai.setBaseUrl(options.baseUrl)\n                }\n            }\n            chat.setConfig(typeof config === 'function' ? await config() : config)\n            const { text } = await chat.talk(messages, {\n                abortController\n            })\n            return text\n        }\n    }\n\n    static createChatRequestWithJsonSchema(params: {\n        axios?: any\n        apiKey: string | (() => Promise<string>)\n        config?: Partial<Pick<Config, 'model' | 'temperature' | 'reasoning'>> | (() => Promise<Partial<Pick<Config, 'model' | 'temperature' | 'reasoning'>>>)\n    }) {\n        return async(messages: any[], { schema, onCancel }: any) => {\n            const openai = new OpenAICtodService(typeof params.apiKey === 'string' ? params.apiKey : await params.apiKey())\n            const chat = openai.createChat()\n            const abortController = new AbortController()\n            if (params.config) {\n                chat.setConfig(typeof params.config === 'function' ? await params.config() : params.config)\n            }\n            if (params.axios) {\n                openai.setAxios(params.axios)\n            }\n            onCancel(() => abortController.abort())\n            const jsonSchema = validateToJsonSchema(schema.output)\n            const { text } = await chat.talk(messages, {\n                abortController,\n                jsonSchema: {\n                    name: 'data',\n                    strict: true,\n                    schema: jsonSchema\n                }\n            })\n            return text\n        }\n    }\n\n    constructor(apiKey = '') {\n        this._apiKey = apiKey\n    }\n\n    /**\n     * @zh \u5982\u679C\u4F60\u6709\u9700\u8981\u7279\u5225\u8A2D\u5B9A axios\uFF0C\u8ACB\u4F7F\u7528\u9019\u65B9\u6CD5\u3002\n     * @en If you need to set axios, please use this method.\n     */\n\n    setAxios(axios: any) {\n        this._axios = axios\n    }\n\n    /**\n     * @zh \u5982\u679C\u4F60\u6709\u9700\u8981\u7279\u5225\u8A2D\u5B9A baseUrl\uFF0C\u8ACB\u4F7F\u7528\u9019\u65B9\u6CD5\u3002\n     * @en If you need to set baseUrl, please use this method.\n     */\n\n    setBaseUrl(baseUrl: string) {\n        this._baseUrl = baseUrl\n    }\n\n    /**\n     * @zh \u8A2D\u5B9A api key\u3002\n     * @en Set api key.\n     */\n\n    setConfiguration(apiKey: string) {\n        this._apiKey = apiKey\n    }\n\n    createChat() {\n        return new OpenAIChat(this)\n    }\n\n    createVision() {\n        return new OpenAIVision(this)\n    }\n\n    createImagesGeneration() {\n        return new OpenAIImagesGeneration(this)\n    }\n}\n", "import { OpenAICtodService } from './index.js'\n\ntype ImageContent = {\n    type: 'image_url' | 'text'\n    text?: string\n    image_url?: {\n        url: string\n        detail?: string\n    }\n}\n\nexport type VisionMessage = {\n    role: 'system' | 'user' | 'assistant'\n    name?: string\n    content: string | ImageContent[]\n}\n\ntype ApiResponse = {\n    id: string\n    object: string\n    created: number\n    model: string\n    usage: {\n        prompt_tokens: number\n        completion_tokens: number\n        total_tokens: number\n    }\n    choices: Array<{\n        message: {\n            role: string\n            content: string\n        }\n        finish_details: {\n            type: string\n        }\n        index: number\n    }>\n}\n\nexport type Config = {\n    /**\n     * @zh \u9078\u64C7\u904B\u884C\u7684\u6A21\u578B\u3002\n     * @en How many chat completion choices to generate for each input message.\n     */\n    model: string\n    /**\n     * @zh \u5192\u96AA\u6307\u6578\uFF0C\u6578\u503C\u7531 0 ~ 2 \u4E4B\u9593\u3002\n     * @en What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n     */\n    temperature: number\n    /**\n     * @zh \u6BCF\u6B21\u5C0D\u8A71\u6700\u591A\u7522\u751F\u5E7E\u500B tokens\u3002\n     * @en How many tokens to complete to.\n     */\n    maxTokens?: number\n}\n\nexport class OpenAIVision {\n    openai: OpenAICtodService\n    config: Config = {\n        model: 'gpt-5',\n        maxTokens: undefined,\n        temperature: 0.7\n    }\n\n    constructor(openai: OpenAICtodService) {\n        this.openai = openai\n    }\n\n    /**\n     * @zh \u6539\u8B8A\u5C0D\u8A71\u7684\u4E00\u4E9B\u8A2D\u5B9A\n     * @en Change some settings of the conversation\n     */\n\n    setConfig(options: Partial<Config>) {\n        Object.assign(this.config, options)\n    }\n\n    /**\n     * @zh \u8FA8\u8B58\u5716\u7247\n     * @en Recognize images\n     */\n\n    async view(messages: VisionMessage[]) {\n        const result = await this.openai._axios.post<ApiResponse>(`${this.openai._baseUrl}/v1/chat/completions`, {\n            model: this.config.model,\n            n: 1,\n            messages,\n            max_tokens: this.config.maxTokens,\n            temperature: this.config.temperature\n        }, {\n            headers: {\n                'Content-Type': 'application/json',\n                'Authorization': `Bearer ${this.openai._apiKey}`\n            }\n        })\n        const choices = result.data.choices || []\n        const message = choices[0]?.message || {\n            role: 'assistant',\n            content: ''\n        }\n        return {\n            id: result?.data.id as string,\n            text: message.content as string,\n            apiResponse: result.data\n        }\n    }\n}\n\nexport type OpenAIChatVisionResponse = Awaited<ReturnType<OpenAIVision['view']>>\n", "import { json } from 'power-helper'\nimport { parseJSONStream } from '../../utils/json.js'\nimport { OpenAICtodService } from './index.js'\n\nexport type ChatGPTMessage = {\n    role: 'system' | 'user' | 'assistant' | string\n    name?: string\n    content: string\n}\n\ntype ApiResponse = {\n    id: string\n    object: string\n    created_at: number\n    status: string\n    completed_at: number\n    error: any\n    incomplete_details: any\n    instructions: any\n    max_output_tokens: any\n    model: string\n    output: Array<{\n        type: string\n        id: string\n        status?: string\n        role?: string\n        summary?: Array<{\n            text: string\n            type: string\n        }>\n        content?: Array<{\n            type: string\n            text: string\n            annotations: Array<any>\n        }>\n    }>\n    parallel_tool_calls: boolean\n    previous_response_id: any\n    reasoning: {\n        effort: any\n        summary: any\n    }\n    store: boolean\n    temperature: number\n    text: {\n        format: {\n            type: string\n        }\n    }\n    tool_choice: string\n    tools: Array<any>\n    top_p: number\n    truncation: string\n    usage: {\n        input_tokens: number\n        input_tokens_details: {\n            cached_tokens: number\n        }\n        output_tokens: number\n        output_tokens_details: {\n            reasoning_tokens: number\n        }\n        total_tokens: number\n    }\n    user: any\n    metadata: {}\n}\n\ntype StreamResponse = {\n    type: string\n    item?: {\n        id: string\n        type: string\n        summary?: Array<any>\n        status?: string\n        content?: Array<any>\n        role?: string\n    }\n    output_index?: number\n    sequence_number: number\n    content_index?: number\n    delta?: string\n    item_id?: string\n    logprobs?: Array<any>\n    obfuscation?: string\n    part?: {\n        type: string\n        annotations: Array<any>\n        logprobs: Array<any>\n        text: string\n    }\n    response?: {\n        id: string\n        object: string\n        created_at: number\n        status: string\n        background: boolean\n        completed_at: number\n        error: any\n        frequency_penalty: number\n        incomplete_details: any\n        instructions: any\n        max_output_tokens: any\n        max_tool_calls: any\n        model: string\n        output: Array<{\n            id: string\n            type: string\n            summary?: Array<any>\n            status?: string\n            content?: Array<{\n                type: string\n                annotations: Array<any>\n                logprobs: Array<any>\n                text: string\n            }>\n            role?: string\n        }>\n        parallel_tool_calls: boolean\n        presence_penalty: number\n        previous_response_id: any\n        prompt_cache_key: any\n        prompt_cache_retention: any\n        reasoning: {\n            effort: string\n            summary: any\n        }\n        safety_identifier: any\n        service_tier: string\n        store: boolean\n        temperature: number\n        text: {\n            format: {\n                type: string\n            }\n            verbosity: string\n        }\n        tool_choice: string\n        tools: Array<any>\n        top_logprobs: number\n        top_p: number\n        truncation: string\n        usage: {\n            input_tokens: number\n            input_tokens_details: {\n                cached_tokens: number\n            }\n            output_tokens: number\n            output_tokens_details: {\n                reasoning_tokens: number\n            }\n            total_tokens: number\n        }\n        user: any\n        metadata: {}\n    }\n}\n\nexport type Config = {\n    /**\n     * @zh \u9078\u64C7\u904B\u884C\u7684\u6A21\u578B'\n     * @en The model to use for this chat completion.\n     */\n    model: string\n    /**\n     * @zh \u5192\u96AA\u6307\u6578\uFF0C\u6578\u503C\u7531 0 ~ 2 \u4E4B\u9593\uFF0C\u8D8A\u4F4E\u56DE\u61C9\u8D8A\u7A69\u5B9A\u3002\n     * @en What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n     */\n    temperature: number\n    /**\n     * @zh \u6BCF\u6B21\u5C0D\u8A71\u6700\u591A\u7522\u751F\u5E7E\u500B tokens\u3002\n     * @en How many tokens to complete to.\n     */\n    maxTokens?: number\n    /**\n     * @zh \u662F\u5426\u8981\u555F\u7528\u601D\u8003\u3002\n     * @en Whether to enable reasoning.\n     */\n    reasoning?: {\n        effort?: 'none' | 'minimal' | 'low' | 'medium' | 'high' | 'xhigh'\n        summary?: 'concise' | 'detailed' | 'auto'\n    }\n}\n\nexport class OpenAIChat {\n    openai: OpenAICtodService\n    config: Config = {\n        model: 'gpt-5',\n        temperature: 1,\n        maxTokens: undefined\n    }\n\n    constructor(openai: OpenAICtodService) {\n        this.openai = openai\n    }\n\n    /**\n     * @zh \u6539\u8B8A\u5C0D\u8A71\u7684\u4E00\u4E9B\u8A2D\u5B9A\n     * @en Change some settings of the conversation\n     */\n\n    setConfig(options: Partial<Config>) {\n        Object.assign(this.config, options)\n    }\n\n    /**\n     * @zh \u6AA2\u8996\u5167\u5BB9\u662F\u5426\u7B26\u5408 OpenAI \u7684\u5BE9\u67E5\n     * @en View content for OpenAI moderation\n     */\n\n    async moderations(input: string) {\n        const result = await this.openai._axios.post<any>(`${this.openai._baseUrl}/v1/moderations`, {\n            input: input\n        }, {\n            headers: {\n                'Content-Type': 'application/json',\n                'Authorization': `Bearer ${this.openai._apiKey}`\n            }\n        })\n        return {\n            isSafe: result.data.results?.[0]?.flagged === false,\n            result: result.data\n        }\n    }\n\n    /**\n     * @zh \u9032\u884C\u5C0D\u8A71\n     * @en Talk to the AI\n     */\n\n    async talk(messages: ChatGPTMessage[] = [], options?: {\n        jsonSchema?: any\n        abortController?: AbortController\n    }) {\n        const newMessages = json.jpjs(messages)\n        let response_format: any = undefined\n        if (options?.jsonSchema) {\n            response_format = {\n                type: 'json_schema',\n                schema: options.jsonSchema.schema\n            }\n        }\n        const result = await this.openai._axios.post<ApiResponse>(`${this.openai._baseUrl}/v1/responses`, {\n            model: this.config.model,\n            input: newMessages,\n            temperature: this.config.temperature,\n            max_output_tokens: this.config.maxTokens,\n            reasoning: this.config.reasoning,\n            text: response_format == null\n                ? undefined\n                : {\n                    format: {\n                        ...response_format,\n                        name: 'response_format'\n                    }\n                }\n        }, {\n            signal: options?.abortController?.signal,\n            headers: {\n                'Content-Type': 'application/json',\n                'Authorization': `Bearer ${this.openai._apiKey}`\n            }\n        })\n        const outputText = result.data.output.find(e => e.type === 'message')?.content?.find(e => e.type === 'output_text')\n        const reasoningText = result.data.output.find(e => e.type === 'reasoning')?.summary?.find(e => e.type === 'summary_text')\n        const message = {\n            role: 'assistant',\n            content: outputText?.text || ''\n        } as const\n        newMessages.push(message)\n        return {\n            id: result?.data.id as string,\n            text: message.content as string,\n            newMessages,\n            reasoningText: reasoningText?.text,\n            apiResponse: result.data\n        }\n    }\n\n    talkStream(params: {\n        messages: any[]\n        onMessage: (_message: string) => void\n        onEnd: () => void\n        onError: (_error: any) => void\n        onWarn?: (_warn: any) => void\n        onThinking?: (_message: string) => void\n    }) {\n        const controller = new AbortController()\n        fetch(`${this.openai._baseUrl}/v1/responses`, {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n                'Authorization': `Bearer ${this.openai._apiKey}`\n            },\n            body: JSON.stringify({\n                model: this.config.model,\n                stream: true,\n                input: params.messages,\n                max_output_tokens: this.config.maxTokens,\n                reasoning: this.config.reasoning\n            }),\n            signal: controller.signal\n        }).then(async response => {\n            if (response.ok === false) {\n                throw new Error(`HTTP error! status: ${response.status}`)\n            }\n            let lastChunk = ''\n            const reader = response.body?.pipeThrough(new TextDecoderStream()).getReader()\n            if (!reader) {\n                throw new Error('Can not get reader')\n            }\n            while (true) {\n                const { value, done } = await reader.read()\n                if (done) {\n                    break\n                }\n                let dataList = value.split('\\n').filter(v => v.startsWith('data:'))\n                for (let data of dataList) {\n                    const response = parseJSONStream<StreamResponse>(lastChunk + data.slice(5))\n                    for (const item of response.items) {\n                        if (item.type === 'response.reasoning_summary_text.delta') {\n                            params.onThinking && params.onThinking(item.delta || '')\n                        }\n                        if (item.type === 'response.output_text.delta') {\n                            params.onMessage(item.delta || '')\n                        }\n                        if (item.type === 'response.completed') {\n                            params.onEnd()\n                        }\n                    }\n                    lastChunk = response.lastChunk\n                }\n            }\n        }).catch(error => {\n            if (error.name === 'AbortError') {\n                params.onEnd()\n            } else {\n                params.onError(error)\n            }\n        })\n        return {\n            cancel: () => controller.abort()\n        }\n    }\n\n    /**\n     * @zh \u958B\u555F\u6301\u7E8C\u6027\u5C0D\u8A71\n     */\n\n    async keepTalk(prompt: string | string[], oldMessages: ChatGPTMessage[] = []) {\n        const result = await this.talk([\n            ...oldMessages,\n            {\n                role: 'user',\n                content: Array.isArray(prompt) ? prompt.join('\\n') : prompt\n            }\n        ])\n        return {\n            result,\n            nextTalk: (prompt: string | string[]) => this.keepTalk(prompt, result.newMessages)\n        }\n    }\n}\n\nexport type OpenAIChatTalkResponse = Awaited<ReturnType<OpenAIChat['talk']>>\n", "import { OpenAICtodService } from './index.js'\n\ntype ApiResponse = {\n    created: string\n    data: {\n        b64_json: string\n    }[]\n}\n\ntype Config = {\n    /**\n     * @zh \u6A21\u578B\uFF0C\u652F\u63F4 dall-e-2 \u548C dall-e-3\n     * @en Model, support dall-e-2 and dall-e-3\n     */\n    model: 'dall-e-2' | 'dall-e-3'\n    /**\n     * @zh \u89E3\u6790\u5EA6\uFF0C\u4F8B\u5982 1024x1024\n     * @en Resolution, for example 1024x1024\n     */\n    size: `${number}x${number}`\n}\n\nexport class OpenAIImagesGeneration {\n    private openai: OpenAICtodService\n    private config: Config = {\n        model: 'dall-e-2',\n        size: '1024x1024'\n    }\n\n    constructor(openai: OpenAICtodService) {\n        this.openai = openai\n    }\n\n    /**\n     * @zh \u6539\u8B8A\u5C0D\u8A71\u7684\u4E00\u4E9B\u8A2D\u5B9A\n     * @en Change some settings of the conversation\n     */\n\n    setConfig(options: Partial<Config>) {\n        Object.assign(this.config, options)\n    }\n\n    /**\n     * @zh \u7522\u751F\u5716\u7247\n     * @en Generate image\n     */\n\n    async create(prompt: string) {\n        const result = await this.openai._axios.post<ApiResponse>(`${this.openai._baseUrl}/v1/images/generations`, {\n            prompt,\n            n: 1,\n            size: this.config.size,\n            model: this.config.model,\n            response_format: 'b64_json'\n        }, {\n            timeout: 1000 * 60 * 5,\n            headers: {\n                'Content-Type': 'application/json',\n                'Authorization': `Bearer ${this.openai._apiKey}`\n            }\n        })\n        return result.data\n    }\n}\n", "import axios, { AxiosInstance } from 'axios'\nimport { s2t, t2s } from '../../utils/chinese-conv.js'\nimport { validateToJsonSchema } from '../../utils/validate.js'\nimport { LlamaCppCompletion, Config } from './completion.js'\n\nexport class LlamaCppCtodService {\n    _axios = axios.create()\n\n    static createChatRequestWithJsonSchema(params: {\n        axios?: AxiosInstance\n        config: Partial<Config> | (() => Promise<Partial<Config>>)\n        talkOptions?: any\n    }) {\n        return async(messages: any[], { schema, onCancel }: any) => {\n            const ll3cpp = new LlamaCppCtodService()\n            const chat = ll3cpp.createCompletion()\n            const config = typeof params.config === 'function' ? await params.config() : params.config\n            chat.setConfig(config)\n            let formatSchema = validateToJsonSchema(schema.output)\n            if (params.axios) {\n                ll3cpp.setAxios(params.axios)\n            }\n            if (chat.config.autoConvertTraditionalChinese) {\n                formatSchema = JSON.parse(t2s(JSON.stringify(formatSchema)))\n            }\n            const { run, cancel } = chat.talk({\n                options: params.talkOptions,\n                messages: messages,\n                response_format: {\n                    type: 'json_object',\n                    schema: formatSchema\n                }\n            })\n            onCancel(cancel)\n            const { message } = await run()\n            return chat.config.autoConvertTraditionalChinese ? s2t(message) : message\n        }\n    }\n\n    /**\n     * @zh \u5982\u679C\u4F60\u6709\u9700\u8981\u7279\u5225\u8A2D\u5B9A axios\uFF0C\u8ACB\u4F7F\u7528\u9019\u65B9\u6CD5\u3002\n     * @en If you need to set axios, please use this method.\n     */\n\n    setAxios(axios: AxiosInstance) {\n        this._axios = axios\n    }\n\n    /**\n     * @zh \u5EFA\u7ACB \u88DC\u5F37/ \u5C0D\u8A71\u7269\u4EF6\u3002\n     * @en Create completion object.\n     */\n\n    createCompletion() {\n        return new LlamaCppCompletion(this)\n    }\n}\n", "import { LlamaCppCtodService } from './index.js'\nimport { flow, Once } from 'power-helper'\nimport { s2t, t2s } from '../../utils/chinese-conv.js'\nimport { Template } from '@huggingface/jinja'\n\ntype Message = {\n    role: string\n    content: string\n}\n\ntype Options = any\n\nexport type Config = {\n    baseUrl: string\n    headers: Record<string, string>\n    autoConvertTraditionalChinese: boolean\n}\n\ntype Stream = {\n    onMessage: (message: string) => void\n    onEnd?: () => void\n    onWarn?: (error: any) => void\n    onError?: (error: any) => void\n}\n\nclass Requester {\n    private core: LlamaCppCompletion\n    private streamAbortControllers: {\n        id: string\n        controller: AbortController\n    }[] = []\n\n    constructor(core: LlamaCppCompletion) {\n        this.core = core\n    }\n\n    private createAbortController() {\n        const streamAbortController = new AbortController()\n        const streamAbortControllerId = flow.createUuid()\n        this.streamAbortControllers.push({\n            id: streamAbortControllerId,\n            controller: streamAbortController\n        })\n        return {\n            signal: streamAbortController.signal,\n            controllerId: streamAbortControllerId\n        }\n    }\n\n    private removeAbortController(streamAbortControllerId: string) {\n        this.streamAbortControllers = this.streamAbortControllers.filter(e => e.id !== streamAbortControllerId)\n    }\n\n    async stream(params: {\n        path: string\n        data: Record<string, any> | (() => Promise<any>)\n        onMessage: (data: any) => void\n        onEnd: () => void\n        onWarn: (error: any) => void\n        onError: (error: any) => void\n    }) {\n        const { signal, controllerId } = this.createAbortController()\n        const end = () => {\n            this.removeAbortController(controllerId)\n            params.onEnd()\n        }\n        const reader = async(response: Response) => {\n            if (response.body) {\n                let reader = response.body.getReader()\n                let done = false\n                let chunk = ''\n                while (!done) {\n                    const { value, done: readerDone } = await reader.read()\n                    if (value) {\n                        chunk += new TextDecoder('utf-8').decode(value)\n                        const payloads = chunk.split('\\n\\n')\n                        chunk = payloads.pop() || ''\n                        payloads.forEach(payload => {\n                            if (payload.includes('[DONE]')) {\n                                done = true\n                            }\n                            if (payload.startsWith('data:')) {\n                                try {\n                                    const data = JSON.parse(payload.replace('data: ', ''))\n                                    params.onMessage(data)\n                                } catch (error) {\n                                    params.onWarn(error)\n                                }\n                            }\n                        })\n                    }\n                    if (readerDone) {\n                        done = true\n                    }\n                }\n                end()\n            } else {\n                params.onError(new Error('Body not found.'))\n            }\n        }\n        fetch(`${this.core.config.baseUrl}/${params.path}`, {\n            method: 'POST',\n            body: JSON.stringify(typeof params.data === 'function' ? (await params.data()) : params.data),\n            signal,\n            headers: {\n                'Content-Type': 'application/json',\n                ...this.core.config.headers\n            }\n        })\n            .then(reader)\n            .catch(error => {\n                if (error instanceof Error && error.message.includes('The user aborted a request')) {\n                    end()\n                } else {\n                    params.onError(error)\n                }\n            })\n    }\n\n    async fetch(params: {\n        path: string\n        data: any\n    }) {\n        const { signal, controllerId } = this.createAbortController()\n        try {\n            const result = await this.core.core._axios.post(`${this.core.config.baseUrl}/${params.path}`, params.data, {\n                signal,\n                headers: {\n                    'Content-Type': 'application/json',\n                    ...this.core.config.headers\n                }\n            })\n            return {\n                data: result.data\n            }\n        } finally {\n            this.removeAbortController(controllerId)\n        }\n    }\n\n    cancel() {\n        this.streamAbortControllers.forEach(e => e.controller.abort())\n        this.streamAbortControllers = []\n    }\n\n    export() {\n        return {\n            cancel: this.cancel.bind(this)\n        }\n    }\n}\n\nexport class LlamaCppCompletion {\n    private getProp = new Once({\n        handler: async() => {\n            const url = `${this.config.baseUrl}/props`\n            const { data: props } = await this.core._axios.get<{\n                chat_template: string\n                bos_token: string\n                eos_token: string\n            }>(url, {})\n            return props\n        }\n    })\n\n    core: LlamaCppCtodService\n    config: Config = {\n        baseUrl: '',\n        headers: {},\n        autoConvertTraditionalChinese: true\n    }\n\n    constructor(core: LlamaCppCtodService) {\n        this.core = core\n    }\n\n    setConfig(config: Partial<Config>) {\n        this.config = {\n            ...this.config,\n            ...config\n        }\n    }\n\n    completion(params: {\n        options?: Options\n        messages: Message[]\n    }) {\n        const lastMessage = params.messages.at(-1) || ''\n        const requester = new Requester(this)\n        return {\n            ...requester.export(),\n            run: async(): Promise<{\n                message: string\n                fullMessage: string\n            }> => {\n                const props = await this.getProp.run()\n                const template = new Template(props.chat_template)\n                const prompt = template.render({\n                    bos_token: props.bos_token,\n                    messages: params.messages\n                }).slice(0, props.eos_token.length * -1 - 1)\n                const result = await requester.fetch({\n                    path: 'completion',\n                    data: {\n                        ...(params.options || {}),\n                        prompt: this.config.autoConvertTraditionalChinese ? t2s(prompt) : prompt\n                    }\n                })\n                const message = this.config.autoConvertTraditionalChinese ? s2t(result.data.content) : result.data.content\n                return {\n                    message,\n                    fullMessage: `${lastMessage}${message}`\n                }\n            }\n        }\n    }\n\n    completionStream(params: Stream & {\n        messages: Message[]\n        options?: Options\n    }) {\n        const requester = new Requester(this)\n        requester.stream({\n            path: 'completion',\n            onEnd: params.onEnd || (() => null),\n            onMessage: e => {\n                const message = this.config.autoConvertTraditionalChinese ? s2t(e.content) : e.content\n                params.onMessage(message)\n            },\n            onWarn: params.onWarn || (() => null),\n            onError: params.onError || (() => null),\n            data: async() => {\n                const props = await this.getProp.run()\n                const template = new Template(props.chat_template)\n                const prompt = template.render({\n                    bos_token: props.bos_token,\n                    messages: params.messages\n                }).slice(0, props.eos_token.length * -1 - 1)\n                return {\n                    ...(params.options || {}),\n                    prompt: this.config.autoConvertTraditionalChinese ? t2s(prompt) : prompt,\n                    stream: true\n                }\n            }\n        })\n        return requester.export()\n    }\n\n    talk(params: {\n        options?: Options\n        messages: Message[]\n        response_format?: {\n            type: 'json_object'\n            schema: any\n        }\n    }) {\n        const requester = new Requester(this)\n        return {\n            ...requester.export(),\n            run: async(): Promise<{\n                message: string\n            }> => {\n                const result = await requester.fetch({\n                    path: 'v1/chat/completions',\n                    data: {\n                        ...(params.options || {}),\n                        response_format: params.response_format,\n                        messages: params.messages.map(e => {\n                            return {\n                                role: e.role,\n                                content: this.config.autoConvertTraditionalChinese ? t2s(e.content) : e.content\n                            }\n                        })\n                    }\n                })\n                const content = result.data.choices[0].message.content || ''\n                return {\n                    message: this.config.autoConvertTraditionalChinese ? s2t(content) : content\n                }\n            }\n        }\n    }\n\n    talkStream(params: Stream & {\n        options?: Options\n        messages: Message[]\n    }) {\n        const requester = new Requester(this)\n        requester.stream({\n            path: 'v1/chat/completions',\n            onEnd: params.onEnd || (() => null),\n            onMessage: e => {\n                let content = e.choices[0].delta.content\n                if (content) {\n                    const message = this.config.autoConvertTraditionalChinese ? s2t(content) : content\n                    params.onMessage(message)\n                }\n            },\n            onWarn: params.onWarn || (() => null),\n            onError: params.onError || (() => null),\n            data: {\n                ...(params.options || {}),\n                stream: true,\n                messages: params.messages.map(e => {\n                    return {\n                        role: e.role,\n                        content: this.config.autoConvertTraditionalChinese ? t2s(e.content) : e.content\n                    }\n                })\n            }\n        })\n        return requester.export()\n    }\n}\n", "import { json } from 'power-helper'\nimport { GoogleCtodService } from './index.js'\n\n/**\n *  if data:\n *  data: base64 string,\n *  mimeType: image/jpeg,\n */\n\ntype Part = {\n    text: string\n} | {\n    inlineData: {\n        data: string\n        mimeType: string\n    }\n}\n\nexport type GoogleMessage = {\n    role: 'model' | 'user'\n    parts: Part[]\n}\n\nexport type Config = {\n    /**\n     * @zh \u9078\u64C7\u904B\u884C\u7684\u6A21\u578B\u3002\n     * @en What model to use.\n     */\n    model: string\n    maxTokens: number\n    temperature: number\n    thinkingConfig: {\n        enabled: boolean\n        level: 'THINKING_LEVEL_UNSPECIFIED' | 'LOW' | 'HIGH'\n    }\n}\n\nexport class GoogleChat {\n    google: GoogleCtodService\n    config: Config = {\n        model: 'gemini-3-flash-preview',\n        maxTokens: 1024,\n        temperature: 0.7,\n        thinkingConfig: {\n            enabled: false,\n            level: 'THINKING_LEVEL_UNSPECIFIED'\n        }\n    }\n\n    constructor(google: GoogleCtodService) {\n        this.google = google\n    }\n\n    /**\n     * @zh \u6539\u8B8A\u5C0D\u8A71\u7684\u4E00\u4E9B\u8A2D\u5B9A\n     * @en Change some settings of the conversation\n     */\n\n    setConfig(options: Partial<Config>) {\n        Object.assign(this.config, options)\n    }\n\n    static getThinkingConfig(config?: Config['thinkingConfig']) {\n        if (!config) {\n            return undefined\n        }\n        return config.enabled === null\n            ? undefined\n            : {\n                includeThoughts: true,\n                thinkingLevel: config.level as any\n            }\n    }\n\n    /**\n     * @zh \u9032\u884C\u5C0D\u8A71\n     * @en Talk to the AI\n     */\n\n    async talk(messages: GoogleMessage[] = []) {\n        const newMessages = json.jpjs(messages)\n        const response = await this.google.googleGenAI.models.generateContent({\n            model: this.config.model,\n            contents: newMessages,\n            config: {\n                temperature: this.config.temperature,\n                maxOutputTokens: this.config.maxTokens,\n                thinkingConfig: GoogleChat.getThinkingConfig(this.config.thinkingConfig)\n            }\n        })\n        const text = response.text\n        return {\n            text,\n            newMessages: [\n                ...newMessages,\n                {\n                    role: 'model',\n                    parts: [\n                        {\n                            text\n                        }\n                    ]\n                }\n            ]\n        }\n    }\n\n    /**\n     * @zh \u9032\u884C\u5C0D\u8A71\uFF0C\u4E26\u4E14\u4EE5\u4E32\u6D41\u7684\u65B9\u5F0F\u8F38\u51FA\n     * @en Talk to the AI and output in a streaming way\n     */\n\n    talkStream(params: {\n        messages: GoogleMessage[]\n        onMessage: (_message: string) => void\n        onEnd: () => void\n        onThinking?: (_thinking: string) => void\n        onError: (_error: any) => void\n    }) {\n        const state = {\n            controller: new AbortController()\n        }\n        const model = this.google.googleGenAI.models.generateContentStream({\n            model: this.config.model,\n            contents: params.messages,\n            config: {\n                abortSignal: state.controller.signal,\n                temperature: this.config.temperature,\n                maxOutputTokens: this.config.maxTokens,\n                thinkingConfig: GoogleChat.getThinkingConfig(this.config.thinkingConfig)\n            }\n        })\n        model.then(async(stream) => {\n            try {\n                for await (const chunk of stream) {\n                    const parts = chunk.candidates?.[0].content?.parts || []\n                    for (let part of parts) {\n                        if (part.text) {\n                            if (part.thought) {\n                                params.onThinking?.(part.text)\n                            } else {\n                                params.onMessage(part.text)\n                            }\n                        }\n                    }\n                }\n                params.onEnd()\n            } catch (error) {\n                if (state.controller.signal.aborted) {\n                    params.onEnd()\n                } else {\n                    throw error\n                }\n            }\n        })\n            .catch((error) => {\n                params.onError(error)\n            })\n        return {\n            cancel: () => {\n                state.controller.abort()\n            }\n        }\n    }\n}\n\nexport type GoogleChatTalkResponse = Awaited<ReturnType<GoogleChat['talk']>>\n", "import { GoogleCtodService } from './index.js'\n\ntype Config = {\n    model: string\n    size: string\n    aspectRatio: string\n}\n\nexport class GoogleImagesGeneration {\n    private google: GoogleCtodService\n    private config: Config = {\n        model: 'imagen-4.0-generate-001',\n        size: '1K',\n        aspectRatio: '1:1'\n    }\n\n    constructor(google: GoogleCtodService) {\n        this.google = google\n    }\n\n    /**\n     * @zh \u6539\u8B8A\u5C0D\u8A71\u7684\u4E00\u4E9B\u8A2D\u5B9A\n     * @en Change some settings of the conversation\n     */\n\n    setConfig(options: Partial<Config>) {\n        Object.assign(this.config, options)\n    }\n\n    /**\n     * @zh \u7522\u751F\u5716\u7247\n     * @en Generate image\n     */\n\n    async create(prompt: string) {\n        const response = await this.google.googleGenAI.models.generateImages({\n            model: this.config.model,\n            prompt,\n            config: {\n                numberOfImages: 1,\n                aspectRatio: this.config.aspectRatio,\n                imageSize: this.config.size\n            }\n        })\n        return {\n            images: response.generatedImages?.map(e => {\n                return {\n                    url: e.image?.imageBytes || '',\n                    mimeType: e.image?.mimeType || ''\n                }\n            }) || []\n        }\n    }\n}\n", "import { validateToJsonSchema } from '../../utils/validate.js'\nimport { GoogleMessage, GoogleChat, Config } from './chat.js'\nimport { GoogleImagesGeneration } from './images-generation.js'\nimport type { GoogleGenAI } from '@google/genai'\n\ntype GPTContent = {\n    type: 'image_url' | 'text'\n    text?: string\n    image_url?: {\n        url: string\n        detail?: string\n    }\n}\n\ntype GPTMessage = {\n    role: 'system' | 'user' | 'assistant'\n    content: string | GPTContent[]\n}\n\nexport class GoogleCtodService {\n    googleGenAI: GoogleGenAI\n\n    constructor(googleGenAI: any) {\n        this.googleGenAI = googleGenAI\n    }\n\n    static chatGPTMessageToGoogleChatMessage(messages: GPTMessage[]): GoogleMessage[] {\n        const contentToParts = (content: string | GPTMessage['content']): GoogleMessage['parts'] => {\n            if (typeof content === 'string') {\n                return [\n                    {\n                        text: content\n                    }\n                ]\n            } else if (Array.isArray(content)) {\n                return content.map(({ type, image_url, text }): GoogleMessage['parts'][number] => {\n                    if (type === 'image_url') {\n                        // base64\n                        const url = image_url?.url || ''\n                        const mimeType = url.includes('data:image/png') ? 'image/png' : 'image/jpeg'\n                        return {\n                            inlineData: {\n                                data: url.split('base64,')[1] || '',\n                                mimeType\n                            }\n                        }\n                    } else {\n                        return {\n                            text: text || ''\n                        }\n                    }\n                })\n            }\n            return []\n        }\n        return messages.map((message) => {\n            if (message.role === 'user' || message.role === 'system') {\n                return {\n                    role: 'user',\n                    parts: contentToParts(message.content)\n                }\n            } else {\n                return {\n                    role: 'model',\n                    parts: contentToParts(message.content)\n                }\n            }\n        })\n    }\n\n    static createChatRequestWithJsonSchema(params: {\n        googleGenAI: any\n        config: Partial<Omit<Config, 'model'>> | (() => Promise<Partial<Omit<Config, 'model'>>>)\n        model: string\n    }) {\n        const googleGenAI: GoogleGenAI = params.googleGenAI\n        const removeAdditionalProperties = (schema: any) => {\n            if (schema.type === 'object') {\n                delete schema.additionalProperties\n                Object.keys(schema.properties).forEach((key) => {\n                    removeAdditionalProperties(schema.properties[key])\n                })\n            } else if (schema.type === 'array') {\n                removeAdditionalProperties(schema.items)\n            }\n            return schema\n        }\n        return async (messages: any[], { schema, abortController }: any) => {\n            const config = typeof params.config === 'function' ? await params.config() : params.config\n            const response = await googleGenAI.models.generateContent({\n                model: params.model,\n                contents: GoogleCtodService.chatGPTMessageToGoogleChatMessage(messages),\n                config: {\n                    abortSignal: abortController.signal,\n                    maxOutputTokens: config.maxTokens,\n                    temperature: config.temperature,\n                    responseMimeType: 'application/json',\n                    responseJsonSchema: validateToJsonSchema(schema.output),\n                    thinkingConfig: GoogleChat.getThinkingConfig(config.thinkingConfig)\n                }\n            })\n            return response.text || ''\n        }\n    }\n\n    createChat() {\n        return new GoogleChat(this)\n    }\n\n    createImagesGeneration() {\n        return new GoogleImagesGeneration(this)\n    }\n}\n", "import { AnthropicCtodService } from './index.js'\n\ntype AnthropicSdk = AnthropicCtodService['anthropicSdk']\n\nexport type Message = {\n    role: string\n    content: string\n}\n\nexport type Config = {\n    /**\n     * @zh \u9078\u64C7\u904B\u884C\u7684\u6A21\u578B\u3002\n     * @en What model to use.\n     */\n    model: string\n    maxTokens: number\n    temperature: number\n    thinking: boolean\n}\n\nexport class AnthropicChatDataGenerator {\n    private config: () => Config\n    constructor(config: () => Config) {\n        this.config = config\n    }\n\n    /**\n     * \u79FB\u9664 system \u8A0A\u606F\n     */\n\n    private translateMessages(messages: any[]) {\n        return {\n            system: messages.find(e => e.role === 'system')?.content,\n            messages: messages.filter(e => e.role !== 'system')\n        }\n    }\n\n    getThinkingParams() {\n        const config = this.config()\n        const budgetTokens = Math.floor(config.maxTokens * 0.25)\n        return config.thinking === false\n            ? undefined\n            : {\n                budget_tokens: budgetTokens <= 1024 ? 1024 : (budgetTokens > 32000 ? 32000 : budgetTokens),\n                type: 'enabled'\n            } as const\n    }\n\n    createChatAndStructureBody(messages: Message[], jsonSchema: any): Parameters<AnthropicSdk['messages']['create']>[0] {\n        const config = this.config()\n        const translateMessages = this.translateMessages(messages)\n        return {\n            model: config.model,\n            max_tokens: config.maxTokens,\n            temperature: config.temperature,\n            system: translateMessages.system,\n            messages: translateMessages.messages,\n            tools: [\n                {\n                    name: 'data',\n                    description: 'Response Data',\n                    input_schema: jsonSchema\n                }\n            ],\n            tool_choice: {\n                type: 'tool',\n                name: 'data'\n            }\n        }\n    }\n\n    parseChatAndStructureResult(result: Awaited<ReturnType<AnthropicSdk['messages']['create']>>): string {\n        let toolUseContent: any = 'content' in result ? result.content.find(e => e.type === 'tool_use') : null\n        let response = toolUseContent?.input || null\n        if (response == null) {\n            return 'null'\n        }\n        return JSON.stringify(response)\n    }\n\n    createTalkBody(messages: Message[]): Parameters<AnthropicSdk['messages']['create']>[0] {\n        const config = this.config()\n        const newMessages = this.translateMessages(messages)\n        return {\n            model: config.model,\n            max_tokens: config.maxTokens,\n            temperature: config.thinking ? 1 : config.temperature,\n            system: newMessages.system,\n            messages: newMessages.messages,\n            thinking: this.getThinkingParams()\n        }\n    }\n\n    parseTalkResult(result: Awaited<ReturnType<AnthropicSdk['messages']['create']>>): string {\n        let output: string[] = []\n        if ('content' in result) {\n            for (let contentBlock of result.content) {\n                if (contentBlock.type === 'text') {\n                    output.push(contentBlock.text)\n                }\n            }\n        }\n        return output.join('\\n')\n    }\n\n    parseTalkThingsResult(result: Awaited<ReturnType<AnthropicSdk['messages']['create']>>): string[] {\n        let output: string[] = []\n        if ('content' in result) {\n            for (let contentBlock of result.content) {\n                if (contentBlock.type === 'thinking') {\n                    output.push(contentBlock.thinking)\n                }\n            }\n        }\n        return output\n    }\n\n    createTalkStreamBody(messages: Message[]): Parameters<AnthropicSdk['messages']['create']>[0] {\n        const config = this.config()\n        const newMessages = this.translateMessages(messages)\n        return {\n            model: config.model,\n            max_tokens: config.maxTokens,\n            temperature: config.thinking ? 1 : config.temperature,\n            system: newMessages.system,\n            stream: true,\n            thinking: this.getThinkingParams(),\n            messages: newMessages.messages\n        }\n    }\n}\n\nexport class AnthropicChat {\n    anthropic: AnthropicCtodService\n    dataGenerator = new AnthropicChatDataGenerator(() => this.config)\n    config: Config = {\n        model: 'claude-3-5-haiku-latest',\n        thinking: false,\n        maxTokens: 8192,\n        temperature: 0.7\n    }\n\n    constructor(anthropic: AnthropicCtodService) {\n        this.anthropic = anthropic\n    }\n\n    /**\n     * @zh \u6539\u8B8A\u5C0D\u8A71\u7684\u4E00\u4E9B\u8A2D\u5B9A\n     * @en Change some settings of the conversation\n     */\n\n    setConfig(options: Partial<Config>) {\n        Object.assign(this.config, options)\n    }\n\n    /**\n     * @zh \u9032\u884C\u5C0D\u8A71\uFF0C\u4E26\u4E14\u4EE5\u7D50\u69CB\u5316\u7684\u65B9\u5F0F\u8F38\u51FA\n     * @en Talk to the AI and output in a structured way\n     */\n\n    async chatAndStructure(messages: Message[], jsonSchema: any, options?: { abortController?: AbortController }) {\n        const anthropic = this.anthropic.anthropicSdk\n        const body = this.dataGenerator.createChatAndStructureBody(messages, jsonSchema)\n        const msg = await anthropic.messages.create(body, {\n            signal: options?.abortController?.signal\n        })\n        return this.dataGenerator.parseChatAndStructureResult(msg)\n    }\n\n    async chatAndStructureWithDetails(messages: Message[], jsonSchema: any, options?: { abortController?: AbortController }) {\n        const anthropic = this.anthropic.anthropicSdk\n        const body = this.dataGenerator.createChatAndStructureBody(messages, jsonSchema)\n        const msg = await anthropic.messages.create(body, {\n            signal: options?.abortController?.signal\n        })\n        return {\n            data: this.dataGenerator.parseChatAndStructureResult(msg),\n            thinking: this.dataGenerator.parseTalkThingsResult(msg)\n        }\n    }\n\n    /**\n     * @zh \u9032\u884C\u5C0D\u8A71\n     * @en Talk to the AI\n     */\n\n    async talk(messages: Message[] = []) {\n        const anthropic = this.anthropic.anthropicSdk\n        const body = this.dataGenerator.createTalkBody(messages)\n        const msg = await anthropic.messages.create(body)\n        return this.dataGenerator.parseTalkResult(msg)\n    }\n\n    /**\n     * @zh \u9032\u884C\u5C0D\u8A71\uFF0C\u4E26\u4E14\u56DE\u50B3\u8A73\u7D30\u5167\u5BB9\n     * @en Talk to the AI and return detailed content\n     */\n\n    async talkAndDetails(messages: Message[] = []) {\n        const anthropic = this.anthropic.anthropicSdk\n        const body = this.dataGenerator.createTalkBody(messages)\n        const msg = await anthropic.messages.create(body)\n        return {\n            text: this.dataGenerator.parseTalkResult(msg),\n            thinking: this.dataGenerator.parseTalkThingsResult(msg)\n        }\n    }\n\n    /**\n     * @zh \u9032\u884C\u5C0D\u8A71\uFF0C\u4E26\u4E14\u4EE5\u4E32\u6D41\u7684\u65B9\u5F0F\u8F38\u51FA\n     * @en Talk to the AI and output in a streaming way\n     */\n\n    talkStream(params: {\n        messages: Message[]\n        onMessage: (_message: string) => void\n        onThinking?: (_thinking: string) => void\n        onEnd: () => void\n        onError: (_error: any) => void\n    }) {\n        let stream: Extract<Awaited<ReturnType<typeof anthropic.messages.create>>, { controller: any }> | null = null\n        const anthropic = this.anthropic.anthropicSdk\n        const { onThinking, onMessage, onEnd, onError } = params\n        const body = this.dataGenerator.createTalkStreamBody(params.messages)\n        const performStreamedChat = async () => {\n            try {\n                let result = await anthropic.messages.create(body)\n                if (result != null && 'controller' in result) {\n                    stream = result\n                    for await (const messageStream of stream) {\n                        if (messageStream.type === 'content_block_delta') {\n                            if (messageStream.delta.type === 'thinking_delta' && onThinking) {\n                                onThinking(messageStream.delta.thinking)\n                            }\n                            if (messageStream.delta.type === 'text_delta') {\n                                onMessage(messageStream.delta.text)\n                            }\n                        }\n                    }\n                }\n                onEnd()\n            } catch (error) {\n                onError(error)\n            }\n        }\n        performStreamedChat()\n        return {\n            cancel: () => {\n                const int = setInterval(() => {\n                    if (stream && stream.controller) {\n                        stream.controller.abort()\n                        clearInterval(int)\n                    }\n                }, 10)\n            }\n        }\n    }\n}\n\nexport type AnthropicChatTalkResponse = Awaited<ReturnType<AnthropicChat['talk']>>\n", "import { validateToJsonSchema } from '../../utils/validate.js'\nimport { Config, AnthropicChat } from './chat.js'\nimport type { Anthropic } from '@anthropic-ai/sdk'\n\ntype GPTContent = {\n    type: 'image_url' | 'text'\n    text?: string\n    image_url?: {\n        url: string\n        detail?: string\n    }\n}\n\ntype GPTMessage = {\n    role: string\n    content: string | GPTContent[]\n}\n\nexport class AnthropicCtodService {\n    anthropicSdk: Anthropic\n\n    constructor(anthropicSdk: any) {\n        this.anthropicSdk = anthropicSdk\n    }\n\n    static chatGPTMessageToAnthropicChatMessage(messages: GPTMessage[]): any[] {\n        const newMessage = messages.map(e => {\n            return {\n                role: e.role,\n                content: typeof e.content === 'string'\n                    ? e.content\n                    : e.content.map((content) => {\n                        if (content.type === 'image_url') {\n                            const url = content.image_url?.url || ''\n                            return {\n                                type: 'image',\n                                source: {\n                                    type: 'base64',\n                                    media_type: url.slice(5).split(';')[0],\n                                    data: url.split(',')[1]\n                                }\n                            }\n                        }\n                        return {\n                            type: 'text',\n                            text: content.text\n                        }\n                    })\n            }\n        })\n        return newMessage\n    }\n\n    static createChatRequestWithJsonSchema(params: {\n        anthropicSdk: any\n        config?: Partial<Config>\n    }) {\n        const anthropic = new AnthropicCtodService(params.anthropicSdk)\n        const chat = anthropic.createChat()\n        chat.setConfig(params.config || {})\n        return async (messages: any[], { schema, abortController }: any) => {\n            const jsonSchema = validateToJsonSchema(schema.output)\n            const content = await chat.chatAndStructure(messages, jsonSchema, {\n                abortController\n            })\n            return content\n        }\n    }\n\n    createChat() {\n        return new AnthropicChat(this)\n    }\n}\n", "import axios from 'axios'\nimport { XChat, Config } from './chat.js'\nimport { XImagesGeneration } from './images-generation.js'\nimport { validateToJsonSchema } from '../../utils/validate.js'\n\nexport class XCtodService {\n    _axios = axios.create()\n    _apiKey = ''\n\n    static createChatRequest(\n        apiKey: string | (() => Promise<string>),\n        config: Partial<Config> | (() => Promise<Partial<Config>>) = {},\n        options?: {\n            axios?: any\n        }\n    ) {\n        return async(messages: any[], { onCancel }: any) => {\n            const xAi = new XCtodService(typeof apiKey === 'string' ? apiKey : await apiKey())\n            const chat = xAi.createChat()\n            const abortController = new AbortController()\n            if (options && options.axios) {\n                xAi.setAxios(options.axios)\n            }\n            chat.setConfig(typeof config === 'function' ? await config() : config)\n            onCancel(() => abortController.abort())\n            const { text } = await chat.talk(messages, {\n                abortController\n            })\n            return text\n        }\n    }\n\n    static createChatRequestWithJsonSchema(params: {\n        axios?: any\n        apiKey: string | (() => Promise<string>)\n        config?: Partial<Pick<Config, 'model' | 'temperature' | 'reasoning'>> | (() => Promise<Partial<Pick<Config, 'model' | 'temperature' | 'reasoning'>>>)\n    }) {\n        return async(messages: any[], { schema, abortController }: any) => {\n            const xAi = new XCtodService(typeof params.apiKey === 'string' ? params.apiKey : await params.apiKey())\n            const chat = xAi.createChat()\n            if (params.config) {\n                chat.setConfig(typeof params.config === 'function' ? await params.config() : params.config)\n            }\n            if (params.axios) {\n                xAi.setAxios(params.axios)\n            }\n            const jsonSchema = validateToJsonSchema(schema.output)\n            const { text } = await chat.talk(messages, {\n                abortController,\n                jsonSchema: {\n                    name: 'data',\n                    strict: true,\n                    schema: jsonSchema\n                }\n            })\n            return text\n        }\n    }\n\n    constructor(apiKey = '') {\n        this._apiKey = apiKey\n    }\n\n    /**\n     * @zh \u5982\u679C\u4F60\u6709\u9700\u8981\u7279\u5225\u8A2D\u5B9A axios\uFF0C\u8ACB\u4F7F\u7528\u9019\u65B9\u6CD5\u3002\n     * @en If you need to set axios, please use this method.\n     */\n\n    setAxios(axios: any) {\n        this._axios = axios\n    }\n\n    /**\n     * @zh \u8A2D\u5B9A api key\u3002\n     * @en Set api key.\n     */\n\n    setConfiguration(apiKey: string) {\n        this._apiKey = apiKey\n    }\n\n    createChat() {\n        return new XChat(this)\n    }\n\n    createImagesGeneration() {\n        return new XImagesGeneration(this)\n    }\n}\n", "import { json } from 'power-helper'\nimport { XCtodService } from './index.js'\nimport { parseJSONStream } from '../../utils/json.js'\n\nexport type XMessage = {\n    role: 'system' | 'user' | 'assistant'\n    name?: string\n    content: string\n}\n\ntype ApiResponse = {\n    id: string\n    object: string\n    created_at: number\n    status: string\n    completed_at: number\n    error: any\n    incomplete_details: any\n    instructions: any\n    max_output_tokens: any\n    model: string\n    output: Array<{\n        type: string\n        id: string\n        status?: string\n        role?: string\n        summary?: Array<{\n            text: string\n            type: string\n        }>\n        content?: Array<{\n            type: string\n            text: string\n            annotations: Array<any>\n        }>\n    }>\n    parallel_tool_calls: boolean\n    previous_response_id: any\n    reasoning: {\n        effort: any\n        summary: any\n    }\n    store: boolean\n    temperature: number\n    text: {\n        format: {\n            type: string\n        }\n    }\n    tool_choice: string\n    tools: Array<any>\n    top_p: number\n    truncation: string\n    usage: {\n        input_tokens: number\n        input_tokens_details: {\n            cached_tokens: number\n        }\n        output_tokens: number\n        output_tokens_details: {\n            reasoning_tokens: number\n        }\n        total_tokens: number\n    }\n    user: any\n    metadata: {}\n}\n\ntype StreamResponse = {\n    type: string\n    item?: {\n        id: string\n        type: string\n        summary?: Array<any>\n        status?: string\n        content?: Array<any>\n        role?: string\n    }\n    output_index?: number\n    sequence_number: number\n    content_index?: number\n    delta?: string\n    item_id?: string\n    logprobs?: Array<any>\n    obfuscation?: string\n    part?: {\n        type: string\n        annotations: Array<any>\n        logprobs: Array<any>\n        text: string\n    }\n    response?: {\n        id: string\n        object: string\n        created_at: number\n        status: string\n        background: boolean\n        completed_at: number\n        error: any\n        frequency_penalty: number\n        incomplete_details: any\n        instructions: any\n        max_output_tokens: any\n        max_tool_calls: any\n        model: string\n        output: Array<{\n            id: string\n            type: string\n            summary?: Array<any>\n            status?: string\n            content?: Array<{\n                type: string\n                annotations: Array<any>\n                logprobs: Array<any>\n                text: string\n            }>\n            role?: string\n        }>\n        parallel_tool_calls: boolean\n        presence_penalty: number\n        previous_response_id: any\n        prompt_cache_key: any\n        prompt_cache_retention: any\n        reasoning: {\n            effort: string\n            summary: any\n        }\n        safety_identifier: any\n        service_tier: string\n        store: boolean\n        temperature: number\n        text: {\n            format: {\n                type: string\n            }\n            verbosity: string\n        }\n        tool_choice: string\n        tools: Array<any>\n        top_logprobs: number\n        top_p: number\n        truncation: string\n        usage: {\n            input_tokens: number\n            input_tokens_details: {\n                cached_tokens: number\n            }\n            output_tokens: number\n            output_tokens_details: {\n                reasoning_tokens: number\n            }\n            total_tokens: number\n        }\n        user: any\n        metadata: {}\n    }\n}\n\nexport type Config = {\n    /**\n     * @zh \u9078\u64C7\u904B\u884C\u7684\u6A21\u578B'\n     * @en The model to use for this chat completion.\n     */\n    model: string\n    /**\n     * @zh \u5192\u96AA\u6307\u6578\uFF0C\u6578\u503C\u7531 0 ~ 2 \u4E4B\u9593\uFF0C\u8D8A\u4F4E\u56DE\u61C9\u8D8A\u7A69\u5B9A\u3002\n     * @en What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n     */\n    temperature: number\n    /**\n     * @zh \u6BCF\u6B21\u5C0D\u8A71\u6700\u591A\u7522\u751F\u5E7E\u500B tokens\u3002\n     * @en How many tokens to complete to.\n     */\n    maxTokens?: number\n    /**\n     * @zh \u662F\u5426\u8981\u555F\u7528\u601D\u8003\u3002\n     * @en Whether to enable reasoning.\n     */\n    reasoning?: {\n        effort?: 'none' | 'minimal' | 'low' | 'medium' | 'high' | 'xhigh'\n        summary?: 'concise' | 'detailed' | 'auto'\n    }\n}\n\nexport class XChat {\n    xAi: XCtodService\n    config: Config = {\n        model: 'grok-4-1-fast-non-reasoning',\n        temperature: 1,\n        maxTokens: undefined\n    }\n\n    constructor(xAi: XCtodService) {\n        this.xAi = xAi\n    }\n\n    /**\n     * @zh \u6539\u8B8A\u5C0D\u8A71\u7684\u4E00\u4E9B\u8A2D\u5B9A\n     * @en Change some settings of the conversation\n     */\n\n    setConfig(options: Partial<Config>) {\n        Object.assign(this.config, options)\n    }\n\n    /**\n     * @zh \u9032\u884C\u5C0D\u8A71\n     * @en Talk to the AI\n     */\n\n    async talk(messages: XMessage[] = [], options?: {\n        /** \u8981 forceJsonFormat \u70BA true \u624D\u6703\u751F\u6548 */\n        jsonSchema?: any\n        abortController?: AbortController\n    }) {\n        const newMessages = json.jpjs(messages)\n        let response_format: any = undefined\n        if (options?.jsonSchema) {\n            response_format = {\n                type: 'json_schema',\n                schema: options.jsonSchema.schema\n            }\n        }\n        const result = await this.xAi._axios.post<ApiResponse>('https://api.x.ai/v1/responses', {\n            model: this.config.model,\n            input: newMessages,\n            temperature: this.config.temperature,\n            max_output_tokens: this.config.maxTokens,\n            reasoning: this.config.reasoning,\n            text: response_format == null\n                ? undefined\n                : {\n                    format: {\n                        ...response_format,\n                        name: 'response_format'\n                    }\n                }\n        }, {\n            signal: options?.abortController?.signal,\n            headers: {\n                'Content-Type': 'application/json',\n                'Authorization': `Bearer ${this.xAi._apiKey}`\n            }\n        })\n        const outputText = result.data.output.find(e => e.type === 'message')?.content?.find(e => e.type === 'output_text')\n        const reasoningText = result.data.output.find(e => e.type === 'reasoning')?.summary?.find(e => e.type === 'summary_text')\n        const message = {\n            role: 'assistant',\n            content: outputText?.text || ''\n        } as const\n        newMessages.push(message)\n        return {\n            id: result?.data.id as string,\n            text: message.content as string,\n            newMessages,\n            reasoningText: reasoningText?.text,\n            apiResponse: result.data\n        }\n    }\n\n    talkStream(params: {\n        messages: any[]\n        onMessage: (_message: string) => void\n        onEnd: () => void\n        onWarn?: (_warn: any) => void\n        onThinking?: (_message: string) => void\n        onError: (_error: any) => void\n    }) {\n        const controller = new AbortController()\n        fetch('https://api.x.ai/v1/responses', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n                'Authorization': `Bearer ${this.xAi._apiKey}`\n            },\n            body: JSON.stringify({\n                model: this.config.model,\n                stream: true,\n                input: params.messages,\n                max_output_tokens: this.config.maxTokens,\n                reasoning: this.config.reasoning\n            }),\n            signal: controller.signal\n        }).then(async response => {\n            if (response.ok === false) {\n                throw new Error(`HTTP error! status: ${response.status}`)\n            }\n            let lastChunk = ''\n            const reader = response.body?.pipeThrough(new TextDecoderStream()).getReader()\n            if (!reader) {\n                throw new Error('Can not get reader')\n            }\n            while (true) {\n                const { value, done } = await reader.read()\n                if (done) {\n                    break\n                }\n                let dataList = value.split('\\n').filter(v => v.startsWith('data:'))\n                for (let data of dataList) {\n                    const response = parseJSONStream<StreamResponse>(lastChunk + data.slice(5))\n                    for (const item of response.items) {\n                        if (item.type === 'response.reasoning_summary_text.delta') {\n                            params.onThinking && params.onThinking(item.delta || '')\n                        }\n                        if (item.type === 'response.output_text.delta') {\n                            params.onMessage(item.delta || '')\n                        }\n                        if (item.type === 'response.completed') {\n                            params.onEnd()\n                        }\n                    }\n                    lastChunk = response.lastChunk\n                }\n            }\n        }).catch(error => {\n            if (error.name === 'AbortError') {\n                params.onEnd()\n            } else {\n                params.onError(error)\n            }\n        })\n        return {\n            cancel: () => controller.abort()\n        }\n    }\n\n    /**\n     * @zh \u958B\u555F\u6301\u7E8C\u6027\u5C0D\u8A71\n     */\n\n    async keepTalk(prompt: string | string[], oldMessages: XMessage[] = []) {\n        const result = await this.talk([\n            ...oldMessages,\n            {\n                role: 'user',\n                content: Array.isArray(prompt) ? prompt.join('\\n') : prompt\n            }\n        ])\n        return {\n            result,\n            nextTalk: (prompt: string | string[]) => this.keepTalk(prompt, result.newMessages)\n        }\n    }\n}\n", "import { XCtodService } from './index.js'\n\ntype ApiResponse = {\n    created: string\n    data: {\n        b64_json: string\n    }[]\n}\n\ntype Config = {\n    /**\n     * @zh \u6A21\u578B\uFF0C\u652F\u63F4 grok-2-image\n     * @en Model, support grok-2-image\n     */\n    model: 'grok-2-image'\n}\n\nexport class XImagesGeneration {\n    private xAi: XCtodService\n    private config: Config = {\n        model: 'grok-2-image'\n    }\n\n    constructor(xAi: XCtodService) {\n        this.xAi = xAi\n    }\n\n    /**\n     * @zh \u6539\u8B8A\u5C0D\u8A71\u7684\u4E00\u4E9B\u8A2D\u5B9A\n     * @en Change some settings of the conversation\n     */\n\n    setConfig(options: Partial<Config>) {\n        Object.assign(this.config, options)\n    }\n\n    /**\n     * @zh \u7522\u751F\u5716\u7247\n     * @en Generate image\n     */\n\n    async create(prompt: string) {\n        const result = await this.xAi._axios.post<ApiResponse>('https://api.x.ai/v1/images/generations', {\n            prompt,\n            n: 1,\n            model: this.config.model,\n            response_format: 'b64_json'\n        }, {\n            timeout: 1000 * 60 * 5,\n            headers: {\n                'Content-Type': 'application/json',\n                'Authorization': `Bearer ${this.xAi._apiKey}`\n            }\n        })\n        return result.data\n    }\n}\n"],
  "mappings": "uOAAA,IAAAA,GAAA,GAAAC,EAAAD,GAAA,mBAAAE,GAAA,2BAAAC,GAAA,mBAAAC,GAAA,gBAAAC,GAAA,eAAAC,KCEA,OAAoB,SAAAC,OAAa,eAwB1B,IAAMC,EAAN,KAGL,CAGE,YAAYC,EAAkC,CAF9CC,EAAA,cAAS,IAAIC,IACbD,EAAA,gBAEI,KAAK,QAAUD,CACnB,CAEA,IAAIA,EAAoC,CACpC,MAAO,CACH,SAAU,KACV,OAAAA,EACA,KAAOG,GAAqC,CAAE,KAAK,OAAO,KAAK,UAAWA,CAAI,CAAE,EAChF,QAAUC,GAAkB,CAAE,KAAK,OAAO,GAAG,UAAWA,CAAQ,CAAE,EAClE,cAAe,IACnB,CACJ,CACJ,EC3CA,IAAOC,GAAQ,IAAIC,EAAiB,CAChC,KAAM,QACN,OAAQC,IACG,CACH,MAAOA,EAAE,OAAO,EAAE,QAAQ,CAAC,EAC3B,UAAWA,EAAE,QAAQ,EAAE,QAAQ,EAAI,CACvC,GAEJ,YAAa,KACF,CAAC,GAEZ,UAAU,CAAE,IAAAC,EAAK,OAAAC,EAAQ,OAAAC,CAAO,EAAG,CAC/BD,EAAO,cAAe,MAAM,CAAE,MAAAE,EAAO,MAAAC,EAAO,SAAAC,EAAU,eAAAC,CAAe,IAAM,CACnEH,GAASD,EAAO,QACZA,EAAO,WACPF,EAAI,MAAM,oBAAoBG,CAAK,SAAS,EAEhDG,EAAeD,CAAQ,EACvBD,EAAM,EAEd,CAAC,CACL,CACJ,CAAC,ECtBD,IAAOG,GAAQ,IAAIC,EAAiB,CAChC,KAAM,YACN,OAAQC,IACG,CACH,OAAQA,EAAE,QAAQ,EAAE,QAAQ,EAAK,CACrC,GAEJ,YAAa,KACF,CAAC,GAEZ,UAAU,CAAE,OAAAC,EAAQ,IAAAC,EAAK,OAAAC,CAAO,EAAG,CAC/BA,EAAO,aAAc,MAAM,CAAE,gBAAAC,EAAiB,SAAAC,CAAS,IAAM,CACzDH,EAAI,MAAM,QAAS,CAAE,MAAO,OAAQ,CAAC,EACjCD,EAAO,OACPC,EAAI,MAAM;AAAA,EAAO,KAAK,UAAUG,EAAU,KAAM,CAAC,CAAC,EAElDH,EAAI,MAAM;AAAA,EAAOE,CAAe,CAExC,CAAC,EACDD,EAAO,YAAa,MAAM,CAAE,UAAAG,CAAU,IAAM,CACxCJ,EAAI,MAAM,WAAY,CAAE,MAAO,MAAO,CAAC,EACvCA,EAAI,MAAM;AAAA,EAAOI,CAAS,CAC9B,CAAC,EACDH,EAAO,YAAa,MAAM,CAAE,OAAAI,CAAO,IAAM,CACrCL,EAAI,MAAM,UAAW,CAAE,MAAO,QAAS,CAAC,EACxC,GAAI,CACAA,EAAI,MAAM;AAAA,EAAO,KAAK,UAAUK,EAAQ,KAAM,CAAC,CAAC,CACpD,MAAgB,CACZL,EAAI,MAAM;AAAA,EAAOK,CAAM,CAC3B,CACJ,CAAC,CACL,CACJ,CAAC,ECjCD,OAAS,SAAAC,GAAO,QAAAC,GAAM,YAAAC,OAAgB,eAWtC,IAAMC,EAAS,CACX,MAAO,EACP,SAAU,GACd,EAEMC,EAAQ,CACV,MAAO,IAAIJ,GACX,SAAU,KACV,UAAW,CAAC,EACZ,UAAW,CAAC,CAChB,EAEOK,EAAQ,CAMX,MAAOD,EAAM,MAOb,OAAAD,EAOA,cAAe,IAAM,CACbC,EAAM,WACNA,EAAM,SAAS,MAAM,EACrBA,EAAM,SAAW,KAEzB,EAOA,OAAQ,IAAIE,EAAiB,CACzB,KAAM,UACN,OAAQ,KACG,CAAC,GAEZ,YAAa,KACF,CAAC,GAEZ,UAAU,CAAE,OAAAC,CAAO,EAAG,CACdH,EAAM,UAAY,OAClBA,EAAM,SAAW,IAAIF,GACrBE,EAAM,SAAS,IAAI,aAAc,IAAM,SAAW,CAC9C,IAAMI,EAAM,KAAK,IAAI,EAIrB,GAHAJ,EAAM,UAAYA,EAAM,UAAU,OAAOK,GAC9BD,EAAMC,EAAON,EAAO,QAC9B,EACGC,EAAM,UAAU,SAAWD,EAAO,MAAO,CACzC,IAAIO,EAASN,EAAM,UAAU,MAAM,EAC/BM,IACAN,EAAM,UAAU,KAAK,KAAK,IAAI,CAAC,EAC/BA,EAAM,MAAM,KAAK,MAAO,CACpB,GAAIM,CACR,CAAC,EAET,MAAWN,EAAM,UAAU,CAAC,GACxBA,EAAM,MAAM,KAAK,iBAAkB,CAC/B,SAAU,KAAK,MAAM,IAAMI,EAAMJ,EAAM,UAAU,CAAC,GAAK,GAAI,CAC/D,CAAC,CAET,CAAC,EACDA,EAAM,SAAS,KAAK,GAExBG,EAAO,aAAc,SAAW,CAC5B,IAAMI,EAAMV,GAAK,WAAW,EAC5B,OAAAG,EAAM,UAAU,KAAKO,CAAG,EACjB,IAAI,QAAQC,GAAW,CAC1BR,EAAM,MAAM,GAAG,MAAO,CAAC,CAAE,GAAAS,CAAG,EAAG,CAAE,IAAAC,CAAI,IAAM,CACnCD,IAAOF,IACPG,EAAI,EACJF,EAAQ,EAEhB,CAAC,CACL,CAAC,CACL,CAAC,CACL,CACJ,CAAC,CACL,ECpGA,IAAOG,GAAQ,IAAIC,EAAiB,CAChC,KAAM,OACN,OAAQC,IACG,CACH,KAAMA,EAAE,OAAO,CACnB,GAEJ,YAAa,KACF,CAAC,GAEZ,UAAU,CAAE,OAAAC,EAAQ,OAAAC,CAAO,EAAG,CAC1BD,EAAO,QAAS,MAAM,CAAE,SAAAE,EAAU,eAAAC,CAAe,IAAM,CACnDA,EAAe,CACX,CACI,KAAM,OACN,QAAS,2BAAOF,EAAO,IAAI,QAC/B,EACA,CACI,KAAM,YACN,QAAS,mDAAWA,EAAO,IAAI,oEACnC,EACA,GAAGC,CACP,CAAC,CACL,CAAC,CACL,CACJ,CAAC,ELjBM,IAAME,GAAiBC,GAOjBC,GAAcC,GAOdC,GAAgBC,EAAQ,OAMxBC,GAAyBD,EAOzBE,GAAaC,GMrC1B,IAAAC,GAAA,GAAAC,EAAAD,GAAA,yBAAAE,GAAA,sCAAAC,GAAA,sCAAAC,KAAA,OAAOC,OAAgB,aACvB,OAAS,UAAAC,OAAc,eAYhB,IAAMJ,GAAsB,CAACK,EAA6BC,IACtD,CACH,GAAI,MAAM,QAAQD,CAAQ,EAAIA,EAAW,CAACA,CAAQ,EAClD,yGACA,IACA,OAAO,QAAQC,CAAM,EAAE,IAAI,CAAC,CAACC,EAAKC,CAAK,IAC5B,CACH,MAAMA,EAAM,IAAI,MAChB,IAAID,CAAG,MAAM,KAAK,UAAUC,EAAM,OAAO,CAAC,EAC9C,EAAE,KAAK;AAAA,CAAI,CACd,EAAE,KAAK;AAAA,CAAK,EACb,GACJ,EAAE,KAAK;AAAA,CAAI,EAQFP,GAAoC,CAC7CO,EACAH,EACAC,IACC,CACD,IAAMG,EAAaN,GAAW,OAAO,EAErC,OAAAM,EAAW,eAAe,OAAQ,SAAoBD,EAAO,CACzD,OAAO,KAAK,UAAUA,CAAK,CAC/B,CAAC,EAEDC,EAAW,eAAe,MAAO,SAAoBD,EAAO,CACxD,OAAO,KAAK,QAAUA,EAAQ,KAAK,OAAOA,CAAK,EAAI,EACvD,CAAC,EAEDC,EAAW,eAAe,QAAS,UAAoB,CACnD,OAAO,KAAK,UAAUL,GAAO,KAAK,KAAM,CAAC,QAAQ,CAAC,CAAC,CACvD,CAAC,EAEDK,EAAW,eAAe,OAAQ,SAAoBD,EAAO,CACzD,OAAO,MAAM,QAAQA,CAAK,EAAIA,EAAM,KAAK,EAAI,KAAK,UAAUA,CAAK,CACrE,CAAC,EAEMC,EAAW,QAAQT,GAAoBK,EAAUC,CAAM,CAAC,EAAEE,CAAK,CAC1E,EAOaN,GAAoC,CAACG,EAA6BC,IACpE,CACH,GAAI,MAAM,QAAQD,CAAQ,EAAIA,EAAW,CAACA,CAAQ,EAClD,0EACA,KAAK,UAAUC,CAAM,CACzB,EAAE,KAAK;AAAA,CAAI,ECrEf,IAAAI,GAAA,GAAAC,EAAAD,GAAA,SAAAE,EAAA,QAAAC,IAAA,OAAS,aAAAC,OAAiB,YAMnB,IAAMD,EAAOE,GACED,GAAU,CACxB,KAAM,KACN,GAAI,IACR,CAAC,EACgBC,CAAI,EAOZH,EAAOG,GACED,GAAU,CACxB,KAAM,KACN,GAAI,IACR,CAAC,EACgBC,CAAI,ECvBzB,OAAOC,OAAW,QAeX,IAAMC,EAAN,MAAMC,CAAW,CAwBpB,YAAYC,EAA0B,CAvBtCC,EAAA,KAAQ,UAwBJ,KAAK,OAASD,CAClB,CAlBA,OAAO,aAAc,CACjB,OAAO,IAAID,EAAW,CAClB,KAAM,cACN,QAAS,MAAOG,GAAS,CACrB,GAAI,CAEA,OADe,KAAK,MAAMA,CAAI,CAElC,MAAgB,CACZ,IAAMC,EAAY,4BACZC,EAAcF,EAAK,MAAMC,CAAS,IAAI,CAAC,GAAK,GAClD,OAAOE,GAAM,MAAMD,CAAW,CAClC,CACJ,CACJ,CAAC,CACL,CAWA,IAAI,MAAO,CACP,OAAO,KAAK,OAAO,IACvB,CAOA,MAAM,KAAKF,EAAc,CAErB,OADe,MAAM,KAAK,OAAO,QAAQA,CAAI,CAEjD,CACJ,EC3DA,OAAS,SAAAI,GAAO,QAAAC,EAAM,QAAAC,GAAM,OAAAC,OAAW,eCFvC,OAAS,KAAAC,EAAG,gBAAAC,OAAoB,MAiBzB,SAASC,EAGdC,EAAaC,EAAmB,CAC9B,OAAOC,EAAE,OAAOD,EAAeC,CAAC,CAAC,EAAE,MAAMF,GAAU,CAAC,CAAC,CAGzD,CAEO,SAASG,EAAsDH,EAAiB,CACnF,IAAMI,EAASC,GAAaH,EAAE,OAAOF,EAAO,CAAC,CAAC,EAC9C,cAAOI,EAAO,QACPA,CACX,CCzBO,IAAME,EAAN,KAAkB,CAIrB,YAAYC,EAAYC,EAA2B,CAHnDC,EAAA,qBAAgB,IAChBA,EAAA,mBAA4B,CAAC,GAC7BA,EAAA,cAEI,KAAK,MAAQF,EACb,KAAK,YAAcC,CACvB,CACJ,ECsBO,IAAME,EAAN,KAGL,CAGE,YAAYC,EAAgC,CAF5CC,EAAA,KAAQ,UAGJ,KAAK,OAASD,CAClB,CAEA,IAAI,cAA2C,CAC3C,OAAO,IACX,CAEA,IAAI,cAA2C,CAC3C,OAAO,IACX,CAOA,MAAM,QAAQE,EAAkCC,EAK7C,CACC,IAAMC,EAAS,KAAK,OAAO,MAAQC,EAASH,EAAM,KAAK,OAAO,KAAK,EAAIA,EACjEI,EAAS,KAAK,OAAO,SAAW,MAAM,KAAK,OAAO,SAASF,EAAQD,CAAO,EAAI,GACpF,MAAO,CACH,OAAAC,EACA,OAAQ,MAAM,QAAQE,CAAM,EAAIA,EAAO,KAAK;AAAA,CAAI,EAAIA,CACxD,CACJ,CAEA,aAAc,CACV,MAAO,CACH,MAAO,KAAK,OAAO,MACnB,OAAQ,KAAK,OAAO,MACxB,CACJ,CAEA,mBAAmBC,EAAW,CAC1B,KAAK,OAAO,OAASA,CACzB,CAOA,MAAM,MAAMC,EAAc,CACtB,IAAIC,EACAC,EAAa,GACbC,EAA8C,CAAC,EACnD,QAASC,KAAS,KAAK,OAAO,QAC1B,GAAI,CACAH,EAAS,MAAMG,EAAM,KAAKJ,CAAI,EAC9BE,EAAaE,EAAM,IACvB,OAASC,EAAO,CACZJ,EAAS,OACTE,EAAY,KAAK,CACb,KAAMC,EAAM,KACZ,MAAAC,CACJ,CAAC,CACL,CAEJ,GAAI,CAEA,MAAO,CACH,OAFSR,EAASI,EAAQ,KAAK,OAAO,MAAM,EAG5C,WAAAC,EACA,YAAAC,CACJ,CACJ,OAASE,EAAO,CACZ,MAAM,IAAIC,EAAYD,EAAOF,CAAW,CAC5C,CACJ,CACJ,EH7GA,OAAS,KAAAI,OAAS,MAgJX,IAAMC,EAAN,KAML,CAeE,YAAYC,EAAgC,CAd5CC,EAAA,KAAU,cACVA,EAAA,KAAU,OACVA,EAAA,KAAU,OAAO,IAAIC,IACrBD,EAAA,KAAU,UACVA,EAAA,KAAU,UAAU,CAAC,GACrBA,EAAA,KAAU,YAAY,IACtBA,EAAA,KAAU,cACVA,EAAA,KAAU,QAAQ,IAAIE,IAQlB,KAAK,IAAM,IAAIC,GAAIJ,EAAO,MAAQ,SAAS,EAC3C,KAAK,OAASA,EACd,KAAK,WAAa,IAAIK,EAAW,CAC7B,GAAGL,EACH,QAAS,CACLM,EAAW,YAAY,CAC3B,CACJ,CAAC,CACL,CAEU,UAAgB,CACtB,GAAI,KAAK,YAAc,GAAO,CAC1B,KAAK,UAAY,GACjB,IAAMC,EAAU,CACZ,IAAK,KAAK,IACV,OAAQ,KAAK,KAAK,OAAO,KAAK,KAAK,IAAI,EACvC,YAAa,KAAK,KAAK,YAAY,KAAK,KAAK,IAAI,EACjD,WAAY,KAAK,UACrB,EACA,GAAI,KAAK,OAAO,QAAS,CACrB,KAAK,QAAU,OAAO,KAAK,OAAO,SAAY,WAAa,KAAK,OAAO,QAAQ,EAAI,KAAK,OAAO,QAC/F,QAASC,KAAO,KAAK,QACjB,KAAK,QAAQA,CAAG,EAAE,SAAS,QAAQ,UAAU,CACzC,GAAGD,EACH,OAAQ,KAAK,QAAQC,CAAG,EAAE,OAC1B,QAAS,KAAK,QAAQA,CAAG,EAAE,OAC/B,CAAC,CAET,CACA,KAAK,OAAO,UAAUD,CAAO,CACjC,CACJ,CAEA,MAAM,OAAOE,EAAoB,CACzBA,EACA,KAAK,MAAM,KAAK,SAAU,CACtB,UAAAA,CACJ,CAAC,EAED,KAAK,MAAM,KAAK,YAAa,CAAC,CAAC,CAEvC,CAEA,cAA0CC,EAGxC,CACE,KAAK,SAAS,EACd,IAAIC,EAAKC,EAAK,WAAW,EACrBC,EAAa,KACbC,EAAW,GACXC,EAAY,GACZC,EAAkB,IAAI,gBAOpBC,EAAY,CACd,KAAK,MAAM,GAAG,SAAU,CAAC,CAAE,UAAAR,CAAU,IAAM,CACnCA,IAAcE,GACdO,EAAc,CAEtB,CAAC,EACD,KAAK,MAAM,GAAG,YAAa,IAAM,CAC7BA,EAAc,CAClB,CAAC,CACL,EACMC,EAAW,IAAMF,EAAU,QAAQG,GAAKA,EAAE,IAAI,CAAC,EAC/CF,EAAgB,IAAM,CACpBJ,IAAa,KACTC,GAAaF,GACbA,EAAW,EAEfG,EAAgB,MAAM,EACtBF,EAAW,GACXK,EAAS,EAEjB,EACME,EAAYC,GAAmB,CACjCT,EAAa,IAAM,CACfS,EAAG,CACP,CACJ,EAOIC,EAAU,SAAW,CACrB,IAAIC,EAAS,KAAK,WAAW,YAAY,EACrCC,EAAc,KACdC,GAAU,CAAC,EACXC,EAAW,IAAI,IACfC,GAAW,MAAM,KAAK,WAAW,QAAQlB,EAAM,CAC/C,OAAAc,CACJ,CAAC,EACGK,GAAyB,CAAC,EAC1BC,EAAsB,CAAC,EACvBF,GAAS,QACTE,EAAS,KAAK,CACV,KAAM,OACN,QAASF,GAAS,MACtB,CAAC,EAEL,QAASpB,KAAO,KAAK,QACjBkB,GAAQlB,CAAG,EAAI,CACX,KAAOE,GAAc,KAAK,QAAQF,CAAG,EAAE,KAAK,CACxC,GAAAG,EACA,KAAAD,CACJ,CAAC,CACL,EAEJ,aAAM,KAAK,KAAK,OAAO,QAAS,CAC5B,GAAAC,EACA,KAAAD,EACA,OAAAc,EACA,QAAAE,GACA,SAAAI,EACA,SAAAH,EACA,eAAgBI,GAAM,CAClBF,GAAcE,EAAG,IAAIX,IACV,CACH,GAAGA,EACH,QAAS,MAAM,QAAQA,EAAE,OAAO,EAAIA,EAAE,QAAQ,KAAK;AAAA,CAAI,EAAIA,EAAE,OACjE,EACH,CACL,EACA,eAAgBW,GAAM,CAClBD,EAAWC,CACf,EACA,mBAAoBN,GAAU,CAC1B,KAAK,WAAW,mBAAmBA,CAAM,EACzCD,EAAS,KAAK,WAAW,YAAY,CACzC,CACJ,CAAC,EACDM,EAAW,CACP,GAAGD,GACH,GAAGC,CACP,EACA,MAAMlB,EAAK,WAAW,MAAO,CAAE,MAAAoB,EAAO,QAAAC,CAAQ,IAAM,CAChD,GAAID,GAAS,GACT,OAAOC,EAAQ,EAEnB,IAAIC,EAAW,GACXC,EAAY,GACZC,EAAY,GACZC,EAAkBP,EAAS,OAAOV,GAAKA,EAAE,OAAS,MAAM,EAAE,MAAM,EAAE,EAAE,CAAC,GAAG,SAAW,GACvF,GAAI,CACA,MAAM,KAAK,KAAK,OAAO,aAAc,CACjC,GAAAT,EACA,KAAAD,EACA,SAAAoB,EACA,SAAAH,EACA,gBAAAU,CACJ,CAAC,EACD,IAAMC,EAAS,KAAK,OAAO,QAAQR,EAAU,CACzC,GAAAnB,EACA,MAAAqB,EACA,OAAAR,EACA,SAAAH,EACA,SAAAM,EACA,gBAAAX,EACA,QAASoB,CACb,CAAC,EACD,GAAItB,EACID,GACAA,EAAW,EAEfG,EAAgB,MAAM,MAEtB,IAAI,CACAD,EAAY,GACZmB,EAAW,MAAMI,EACjBH,EAAYD,CAChB,QAAE,CACEnB,EAAY,EAChB,CAEAD,IAAa,KACb,MAAM,KAAK,KAAK,OAAO,YAAa,CAChC,GAAAH,EACA,KAAAD,EACA,SAAAwB,EACA,SAAAJ,EACA,UAAAK,EACA,SAAAR,EACA,gBAAAU,EACA,UAAYE,GAAU,CAClB,MAAM,IAAIC,EAAYD,EAAO,CAAC,CAAC,CACnC,EACA,gBAAiBE,GAAQ,CACrBN,EAAYM,CAChB,CACJ,CAAC,EACDhB,GAAU,MAAM,KAAK,WAAW,MAAMU,CAAS,GAAG,OAClD,MAAM,KAAK,KAAK,OAAO,YAAa,CAChC,GAAAxB,EACA,OAAAc,EACA,SAAAE,CACJ,CAAC,GAEL,MAAM,KAAK,KAAK,OAAO,OAAQ,CAC3B,GAAAhB,EACA,SAAAgB,CACJ,CAAC,EACDM,EAAQ,CACZ,OAASM,EAAY,CAEjB,GAAIA,aAAiBC,GAiBjB,GAhBA,MAAM,KAAK,KAAK,OAAO,cAAe,CAClC,GAAA7B,EACA,MAAO4B,EAAM,MACb,MAAAP,EACA,SAAAE,EACA,SAAAJ,EACA,SAAAH,EACA,gBAAAU,EACA,YAAaE,EAAM,YACnB,MAAO,IAAM,CACTH,EAAY,EAChB,EACA,eAAgBL,GAAM,CAClBD,EAAWC,CACf,CACJ,CAAC,EACGK,IAAc,GACd,YAAM,KAAK,KAAK,OAAO,OAAQ,CAC3B,GAAAzB,EACA,SAAAgB,CACJ,CAAC,EACKY,MAGV,aAAM,KAAK,KAAK,OAAO,OAAQ,CAC3B,GAAA5B,EACA,SAAAgB,CACJ,CAAC,EACKY,CAEd,CACJ,CAAC,EACMd,CACX,EASA,MAAO,CACH,GAAAd,EACA,SAVS,SAAW,CACpB,GAAI,CAEA,OADe,MAAMY,EAAQ,CAEjC,QAAE,CACEJ,EAAS,CACb,CACJ,GAGkB,CAClB,CACJ,CAOA,MAAM,QAAoCT,EAAqD,CAC3F,GAAM,CAAE,QAAAa,CAAQ,EAAI,KAAK,cAAcb,CAAI,EAE3C,OADe,MAAMa,CAEzB,CAOA,MAAM,kBAA8Cb,EAAyB,CACzE,KAAK,SAAS,EACd,IAAIC,EAAKC,EAAK,WAAW,EACrBY,EAAS,KAAK,WAAW,YAAY,EACrCE,EAAU,CAAC,EACXC,EAAW,IAAI,IACfC,EAAW,MAAM,KAAK,WAAW,QAAQlB,EAAM,CAC/C,OAAAc,CACJ,CAAC,EACGK,EAAyB,CAAC,EAC1BC,EAAsB,CAAC,EAC3B,OAAIF,EAAS,QACTE,EAAS,KAAK,CACV,KAAM,OACN,QAASF,EAAS,MACtB,CAAC,EAEL,MAAM,KAAK,KAAK,OAAO,QAAS,CAC5B,GAAAjB,EACA,KAAAD,EACA,OAAAc,EACA,QAAAE,EACA,SAAAI,EACA,SAAAH,EACA,eAAgBI,GAAM,CAClBF,EAAcE,EAAG,IAAIX,IACV,CACH,GAAGA,EACH,QAAS,MAAM,QAAQA,EAAE,OAAO,EAAIA,EAAE,QAAQ,KAAK;AAAA,CAAI,EAAIA,EAAE,OACjE,EACH,CACL,EACA,eAAgBW,GAAM,CAClBD,EAAWC,CACf,EACA,mBAAoBN,GAAU,CAC1B,KAAK,WAAW,mBAAmBA,CAAM,EACzCD,EAAS,KAAK,WAAW,YAAY,CACzC,CACJ,CAAC,EAEM,CACH,aAFiBA,EAAO,OAAOkB,EAAC,EAGhC,iBAAkBC,EAAqB,IAAMnB,EAAO,OAAOkB,EAAC,CAAQ,EACpE,gBAAiB,CACb,GAAGb,EACH,GAAGC,CACP,CACJ,CACJ,CACJ,EIhfA,UAAYc,OAAO,MAIZ,IAAMC,EAAN,KAGL,CAEE,YAAYC,EAGT,CAJHC,EAAA,eAKI,KAAK,OAASD,CAClB,CAEA,oBAAmDA,EAEhD,CACC,MAAO,CACH,OAAiDE,GAYtC,IAAIC,EAMT,CACE,OAAQ,KAAO,CAAC,GAChB,QAAUC,GAAY,CAClBJ,GAAQ,UAAUI,CAAO,EACzBA,EAAQ,OAAO,QAAS,MAAM,CAAE,GAAAC,EAAI,QAAAC,EAAS,KAAAC,EAAM,SAAAC,EAAU,eAAAC,EAAgB,mBAAAC,CAAmB,IAAM,CAClG,IAAMC,EAAS,MAAMT,EAAQ,CACzB,GAAAG,EACA,KAAME,EACN,QAAAD,EACA,IAAKM,GACL,YAAcC,GAAa,CACvBJ,EAAeI,EAAS,IAAIC,IACjB,CACH,KAAMA,EAAE,KACR,QAAS,MAAM,QAAQA,EAAE,OAAO,EAAIA,EAAE,QAAQ,KAAK;AAAA,CAAI,EAAIA,EAAE,OACjE,EACH,CAAC,CACN,EACA,SAAAN,CACJ,CAAC,EACDE,EAAmB,IAAMC,CAAM,CACnC,CAAC,CACL,EACA,QAAS,KAAK,OAAO,QAAU,IAAM,KAAK,OAAO,QAAS,EAAI,OAC9D,QAAS,KAAK,OAAO,OACzB,CAAC,CAET,CACJ,CACJ,ECrEO,IAAMI,EAAsBC,GAG9B,CACD,IAAMC,EAAa,CAAC,EAChBC,EAAS,GACTC,EAAQ,EACRC,EAAW,GACXC,EAAa,GACbC,EAAgB,GAEpB,QAASC,EAAI,EAAGA,EAAIP,EAAK,OAAQO,IAAK,CAClC,IAAMC,EAAOR,EAAKO,CAAC,EAEnB,GAAIF,EAAY,CACZA,EAAa,GACTC,IAAeJ,GAAUM,GAC7B,QACJ,CACA,GAAIA,IAAS,KAAM,CACfH,EAAa,GACTC,IAAeJ,GAAUM,GAC7B,QACJ,CACA,GAAIA,IAAS,IAAK,CACdJ,EAAW,CAACA,EACRE,IAAeJ,GAAUM,GAC7B,QACJ,CACA,GAAKJ,EA2BME,IACPJ,GAAUM,WA3BNA,IAAS,IACLL,IAAU,GACVG,EAAgB,GAChBJ,EAAS,KAETA,GAAUM,EAEdL,YACOK,IAAS,KAGhB,GAFAL,IACAD,GAAUM,EACNL,IAAU,GAAKG,EAAe,CAC9B,IAAMG,EAAUP,EAAO,KAAK,EAC5B,GAAIO,EACA,GAAI,CACAR,EAAM,KAAK,KAAK,MAAMQ,CAAO,CAAC,CAClC,MAAQ,CAER,CAEJP,EAAS,GACTI,EAAgB,EACpB,OACOA,IACPJ,GAAUM,EAKtB,CAEA,MAAO,CACH,MAAAP,EACA,UAAWK,EAAgBJ,EAAO,KAAK,EAAI,EAC/C,CACJ,ECjEA,OAAOQ,OAAW,QCyDX,IAAMC,EAAN,KAAmB,CAQtB,YAAYC,EAA2B,CAPvCC,EAAA,eACAA,EAAA,cAAiB,CACb,MAAO,QACP,UAAW,OACX,YAAa,EACjB,GAGI,KAAK,OAASD,CAClB,CAOA,UAAUE,EAA0B,CAChC,OAAO,OAAO,KAAK,OAAQA,CAAO,CACtC,CAOA,MAAM,KAAKC,EAA2B,CAClC,IAAMC,EAAS,MAAM,KAAK,OAAO,OAAO,KAAkB,GAAG,KAAK,OAAO,QAAQ,uBAAwB,CACrG,MAAO,KAAK,OAAO,MACnB,EAAG,EACH,SAAAD,EACA,WAAY,KAAK,OAAO,UACxB,YAAa,KAAK,OAAO,WAC7B,EAAG,CACC,QAAS,CACL,eAAgB,mBAChB,cAAiB,UAAU,KAAK,OAAO,OAAO,EAClD,CACJ,CAAC,EAEKE,GADUD,EAAO,KAAK,SAAW,CAAC,GAChB,CAAC,GAAG,SAAW,CACnC,KAAM,YACN,QAAS,EACb,EACA,MAAO,CACH,GAAIA,GAAQ,KAAK,GACjB,KAAMC,EAAQ,QACd,YAAaD,EAAO,IACxB,CACJ,CACJ,EC3GA,OAAS,QAAAE,OAAY,eAwLd,IAAMC,EAAN,KAAiB,CAQpB,YAAYC,EAA2B,CAPvCC,EAAA,eACAA,EAAA,cAAiB,CACb,MAAO,QACP,YAAa,EACb,UAAW,MACf,GAGI,KAAK,OAASD,CAClB,CAOA,UAAUE,EAA0B,CAChC,OAAO,OAAO,KAAK,OAAQA,CAAO,CACtC,CAOA,MAAM,YAAYC,EAAe,CAC7B,IAAMC,EAAS,MAAM,KAAK,OAAO,OAAO,KAAU,GAAG,KAAK,OAAO,QAAQ,kBAAmB,CACxF,MAAOD,CACX,EAAG,CACC,QAAS,CACL,eAAgB,mBAChB,cAAiB,UAAU,KAAK,OAAO,OAAO,EAClD,CACJ,CAAC,EACD,MAAO,CACH,OAAQC,EAAO,KAAK,UAAU,CAAC,GAAG,UAAY,GAC9C,OAAQA,EAAO,IACnB,CACJ,CAOA,MAAM,KAAKC,EAA6B,CAAC,EAAGH,EAGzC,CACC,IAAMI,EAAcC,GAAK,KAAKF,CAAQ,EAClCG,EACAN,GAAS,aACTM,EAAkB,CACd,KAAM,cACN,OAAQN,EAAQ,WAAW,MAC/B,GAEJ,IAAME,EAAS,MAAM,KAAK,OAAO,OAAO,KAAkB,GAAG,KAAK,OAAO,QAAQ,gBAAiB,CAC9F,MAAO,KAAK,OAAO,MACnB,MAAOE,EACP,YAAa,KAAK,OAAO,YACzB,kBAAmB,KAAK,OAAO,UAC/B,UAAW,KAAK,OAAO,UACvB,KAAME,GAAmB,KACnB,OACA,CACE,OAAQ,CACJ,GAAGA,EACH,KAAM,iBACV,CACJ,CACR,EAAG,CACC,OAAQN,GAAS,iBAAiB,OAClC,QAAS,CACL,eAAgB,mBAChB,cAAiB,UAAU,KAAK,OAAO,OAAO,EAClD,CACJ,CAAC,EACKO,EAAaL,EAAO,KAAK,OAAO,KAAKM,GAAKA,EAAE,OAAS,SAAS,GAAG,SAAS,KAAKA,GAAKA,EAAE,OAAS,aAAa,EAC5GC,EAAgBP,EAAO,KAAK,OAAO,KAAKM,GAAKA,EAAE,OAAS,WAAW,GAAG,SAAS,KAAKA,GAAKA,EAAE,OAAS,cAAc,EAClHE,EAAU,CACZ,KAAM,YACN,QAASH,GAAY,MAAQ,EACjC,EACA,OAAAH,EAAY,KAAKM,CAAO,EACjB,CACH,GAAIR,GAAQ,KAAK,GACjB,KAAMQ,EAAQ,QACd,YAAAN,EACA,cAAeK,GAAe,KAC9B,YAAaP,EAAO,IACxB,CACJ,CAEA,WAAWS,EAOR,CACC,IAAMC,EAAa,IAAI,gBACvB,aAAM,GAAG,KAAK,OAAO,QAAQ,gBAAiB,CAC1C,OAAQ,OACR,QAAS,CACL,eAAgB,mBAChB,cAAiB,UAAU,KAAK,OAAO,OAAO,EAClD,EACA,KAAM,KAAK,UAAU,CACjB,MAAO,KAAK,OAAO,MACnB,OAAQ,GACR,MAAOD,EAAO,SACd,kBAAmB,KAAK,OAAO,UAC/B,UAAW,KAAK,OAAO,SAC3B,CAAC,EACD,OAAQC,EAAW,MACvB,CAAC,EAAE,KAAK,MAAMC,GAAY,CACtB,GAAIA,EAAS,KAAO,GAChB,MAAM,IAAI,MAAM,uBAAuBA,EAAS,MAAM,EAAE,EAE5D,IAAIC,EAAY,GACVC,EAASF,EAAS,MAAM,YAAY,IAAI,iBAAmB,EAAE,UAAU,EAC7E,GAAI,CAACE,EACD,MAAM,IAAI,MAAM,oBAAoB,EAExC,OAAa,CACT,GAAM,CAAE,MAAAC,EAAO,KAAAC,CAAK,EAAI,MAAMF,EAAO,KAAK,EAC1C,GAAIE,EACA,MAEJ,IAAIC,EAAWF,EAAM,MAAM;AAAA,CAAI,EAAE,OAAOG,GAAKA,EAAE,WAAW,OAAO,CAAC,EAClE,QAASC,KAAQF,EAAU,CACvB,IAAML,EAAWQ,EAAgCP,EAAYM,EAAK,MAAM,CAAC,CAAC,EAC1E,QAAWE,KAAQT,EAAS,MACpBS,EAAK,OAAS,yCACdX,EAAO,YAAcA,EAAO,WAAWW,EAAK,OAAS,EAAE,EAEvDA,EAAK,OAAS,8BACdX,EAAO,UAAUW,EAAK,OAAS,EAAE,EAEjCA,EAAK,OAAS,sBACdX,EAAO,MAAM,EAGrBG,EAAYD,EAAS,SACzB,CACJ,CACJ,CAAC,EAAE,MAAMU,GAAS,CACVA,EAAM,OAAS,aACfZ,EAAO,MAAM,EAEbA,EAAO,QAAQY,CAAK,CAE5B,CAAC,EACM,CACH,OAAQ,IAAMX,EAAW,MAAM,CACnC,CACJ,CAMA,MAAM,SAASY,EAA2BC,EAAgC,CAAC,EAAG,CAC1E,IAAMvB,EAAS,MAAM,KAAK,KAAK,CAC3B,GAAGuB,EACH,CACI,KAAM,OACN,QAAS,MAAM,QAAQD,CAAM,EAAIA,EAAO,KAAK;AAAA,CAAI,EAAIA,CACzD,CACJ,CAAC,EACD,MAAO,CACH,OAAAtB,EACA,SAAWsB,GAA8B,KAAK,SAASA,EAAQtB,EAAO,WAAW,CACrF,CACJ,CACJ,ECpVO,IAAMwB,EAAN,KAA6B,CAOhC,YAAYC,EAA2B,CANvCC,EAAA,KAAQ,UACRA,EAAA,KAAQ,SAAiB,CACrB,MAAO,WACP,KAAM,WACV,GAGI,KAAK,OAASD,CAClB,CAOA,UAAUE,EAA0B,CAChC,OAAO,OAAO,KAAK,OAAQA,CAAO,CACtC,CAOA,MAAM,OAAOC,EAAgB,CAczB,OAbe,MAAM,KAAK,OAAO,OAAO,KAAkB,GAAG,KAAK,OAAO,QAAQ,yBAA0B,CACvG,OAAAA,EACA,EAAG,EACH,KAAM,KAAK,OAAO,KAClB,MAAO,KAAK,OAAO,MACnB,gBAAiB,UACrB,EAAG,CACC,QAAS,IACT,QAAS,CACL,eAAgB,mBAChB,cAAiB,UAAU,KAAK,OAAO,OAAO,EAClD,CACJ,CAAC,GACa,IAClB,CACJ,EHzDO,IAAMC,GAAN,MAAMC,CAAkB,CA6D3B,YAAYC,EAAS,GAAI,CA5DzBC,EAAA,cAASC,GAAM,OAAO,GACtBD,EAAA,eAAU,IACVA,EAAA,gBAAW,0BA2DP,KAAK,QAAUD,CACnB,CA1DA,OAAO,kBACHA,EACAG,EAA6D,CAAC,EAC9DC,EAIF,CACE,MAAO,OAAMC,EAAiB,CAAE,gBAAAC,CAAgB,IAAW,CACvD,IAAMC,EAAS,IAAIR,EAAkB,OAAOC,GAAW,SAAWA,EAAS,MAAMA,EAAO,CAAC,EACnFQ,EAAOD,EAAO,WAAW,EAC3BH,IACIA,EAAQ,OACRG,EAAO,SAASH,EAAQ,KAAK,EAE7BA,EAAQ,SACRG,EAAO,WAAWH,EAAQ,OAAO,GAGzCI,EAAK,UAAU,OAAOL,GAAW,WAAa,MAAMA,EAAO,EAAIA,CAAM,EACrE,GAAM,CAAE,KAAAM,CAAK,EAAI,MAAMD,EAAK,KAAKH,EAAU,CACvC,gBAAAC,CACJ,CAAC,EACD,OAAOG,CACX,CACJ,CAEA,OAAO,gCAAgCC,EAIpC,CACC,MAAO,OAAML,EAAiB,CAAE,OAAAM,EAAQ,SAAAC,CAAS,IAAW,CACxD,IAAML,EAAS,IAAIR,EAAkB,OAAOW,EAAO,QAAW,SAAWA,EAAO,OAAS,MAAMA,EAAO,OAAO,CAAC,EACxGF,EAAOD,EAAO,WAAW,EACzBD,EAAkB,IAAI,gBACxBI,EAAO,QACPF,EAAK,UAAU,OAAOE,EAAO,QAAW,WAAa,MAAMA,EAAO,OAAO,EAAIA,EAAO,MAAM,EAE1FA,EAAO,OACPH,EAAO,SAASG,EAAO,KAAK,EAEhCE,EAAS,IAAMN,EAAgB,MAAM,CAAC,EACtC,IAAMO,EAAaC,EAAqBH,EAAO,MAAM,EAC/C,CAAE,KAAAF,CAAK,EAAI,MAAMD,EAAK,KAAKH,EAAU,CACvC,gBAAAC,EACA,WAAY,CACR,KAAM,OACN,OAAQ,GACR,OAAQO,CACZ,CACJ,CAAC,EACD,OAAOJ,CACX,CACJ,CAWA,SAASP,EAAY,CACjB,KAAK,OAASA,CAClB,CAOA,WAAWa,EAAiB,CACxB,KAAK,SAAWA,CACpB,CAOA,iBAAiBf,EAAgB,CAC7B,KAAK,QAAUA,CACnB,CAEA,YAAa,CACT,OAAO,IAAIgB,EAAW,IAAI,CAC9B,CAEA,cAAe,CACX,OAAO,IAAIC,EAAa,IAAI,CAChC,CAEA,wBAAyB,CACrB,OAAO,IAAIC,EAAuB,IAAI,CAC1C,CACJ,EI7GA,OAAOC,OAA8B,QCCrC,OAAS,QAAAC,GAAM,QAAAC,OAAY,eAE3B,OAAS,YAAAC,OAAgB,qBAsBzB,IAAMC,EAAN,KAAgB,CAOZ,YAAYC,EAA0B,CANtCC,EAAA,KAAQ,QACRA,EAAA,KAAQ,yBAGF,CAAC,GAGH,KAAK,KAAOD,CAChB,CAEQ,uBAAwB,CAC5B,IAAME,EAAwB,IAAI,gBAC5BC,EAA0BC,GAAK,WAAW,EAChD,YAAK,uBAAuB,KAAK,CAC7B,GAAID,EACJ,WAAYD,CAChB,CAAC,EACM,CACH,OAAQA,EAAsB,OAC9B,aAAcC,CAClB,CACJ,CAEQ,sBAAsBA,EAAiC,CAC3D,KAAK,uBAAyB,KAAK,uBAAuB,OAAOE,GAAKA,EAAE,KAAOF,CAAuB,CAC1G,CAEA,MAAM,OAAOG,EAOV,CACC,GAAM,CAAE,OAAAC,EAAQ,aAAAC,CAAa,EAAI,KAAK,sBAAsB,EACtDC,EAAM,IAAM,CACd,KAAK,sBAAsBD,CAAY,EACvCF,EAAO,MAAM,CACjB,EACMI,EAAS,MAAMC,GAAuB,CACxC,GAAIA,EAAS,KAAM,CACf,IAAID,EAASC,EAAS,KAAK,UAAU,EACjCC,EAAO,GACPC,EAAQ,GACZ,KAAO,CAACD,GAAM,CACV,GAAM,CAAE,MAAAE,EAAO,KAAMC,CAAW,EAAI,MAAML,EAAO,KAAK,EACtD,GAAII,EAAO,CACPD,GAAS,IAAI,YAAY,OAAO,EAAE,OAAOC,CAAK,EAC9C,IAAME,EAAWH,EAAM,MAAM;AAAA;AAAA,CAAM,EACnCA,EAAQG,EAAS,IAAI,GAAK,GAC1BA,EAAS,QAAQC,GAAW,CAIxB,GAHIA,EAAQ,SAAS,QAAQ,IACzBL,EAAO,IAEPK,EAAQ,WAAW,OAAO,EAC1B,GAAI,CACA,IAAMC,EAAO,KAAK,MAAMD,EAAQ,QAAQ,SAAU,EAAE,CAAC,EACrDX,EAAO,UAAUY,CAAI,CACzB,OAASC,EAAO,CACZb,EAAO,OAAOa,CAAK,CACvB,CAER,CAAC,CACL,CACIJ,IACAH,EAAO,GAEf,CACAH,EAAI,CACR,MACIH,EAAO,QAAQ,IAAI,MAAM,iBAAiB,CAAC,CAEnD,EACA,MAAM,GAAG,KAAK,KAAK,OAAO,OAAO,IAAIA,EAAO,IAAI,GAAI,CAChD,OAAQ,OACR,KAAM,KAAK,UAAU,OAAOA,EAAO,MAAS,WAAc,MAAMA,EAAO,KAAK,EAAKA,EAAO,IAAI,EAC5F,OAAAC,EACA,QAAS,CACL,eAAgB,mBAChB,GAAG,KAAK,KAAK,OAAO,OACxB,CACJ,CAAC,EACI,KAAKG,CAAM,EACX,MAAMS,GAAS,CACRA,aAAiB,OAASA,EAAM,QAAQ,SAAS,4BAA4B,EAC7EV,EAAI,EAEJH,EAAO,QAAQa,CAAK,CAE5B,CAAC,CACT,CAEA,MAAM,MAAMb,EAGT,CACC,GAAM,CAAE,OAAAC,EAAQ,aAAAC,CAAa,EAAI,KAAK,sBAAsB,EAC5D,GAAI,CAQA,MAAO,CACH,MARW,MAAM,KAAK,KAAK,KAAK,OAAO,KAAK,GAAG,KAAK,KAAK,OAAO,OAAO,IAAIF,EAAO,IAAI,GAAIA,EAAO,KAAM,CACvG,OAAAC,EACA,QAAS,CACL,eAAgB,mBAChB,GAAG,KAAK,KAAK,OAAO,OACxB,CACJ,CAAC,GAEgB,IACjB,CACJ,QAAE,CACE,KAAK,sBAAsBC,CAAY,CAC3C,CACJ,CAEA,QAAS,CACL,KAAK,uBAAuB,QAAQ,GAAK,EAAE,WAAW,MAAM,CAAC,EAC7D,KAAK,uBAAyB,CAAC,CACnC,CAEA,QAAS,CACL,MAAO,CACH,OAAQ,KAAK,OAAO,KAAK,IAAI,CACjC,CACJ,CACJ,EAEaY,EAAN,KAAyB,CAoB5B,YAAYpB,EAA2B,CAnBvCC,EAAA,KAAQ,UAAU,IAAIoB,GAAK,CACvB,QAAS,SAAW,CAChB,IAAMC,EAAM,GAAG,KAAK,OAAO,OAAO,SAC5B,CAAE,KAAMC,CAAM,EAAI,MAAM,KAAK,KAAK,OAAO,IAI5CD,EAAK,CAAC,CAAC,EACV,OAAOC,CACX,CACJ,CAAC,GAEDtB,EAAA,aACAA,EAAA,cAAiB,CACb,QAAS,GACT,QAAS,CAAC,EACV,8BAA+B,EACnC,GAGI,KAAK,KAAOD,CAChB,CAEA,UAAUwB,EAAyB,CAC/B,KAAK,OAAS,CACV,GAAG,KAAK,OACR,GAAGA,CACP,CACJ,CAEA,WAAWlB,EAGR,CACC,IAAMmB,EAAcnB,EAAO,SAAS,GAAG,EAAE,GAAK,GACxCoB,EAAY,IAAI3B,EAAU,IAAI,EACpC,MAAO,CACH,GAAG2B,EAAU,OAAO,EACpB,IAAK,SAGC,CACF,IAAMH,EAAQ,MAAM,KAAK,QAAQ,IAAI,EAE/BI,EADW,IAAIC,GAASL,EAAM,aAAa,EACzB,OAAO,CAC3B,UAAWA,EAAM,UACjB,SAAUjB,EAAO,QACrB,CAAC,EAAE,MAAM,EAAGiB,EAAM,UAAU,OAAS,GAAK,CAAC,EACrCM,EAAS,MAAMH,EAAU,MAAM,CACjC,KAAM,aACN,KAAM,CACF,GAAIpB,EAAO,SAAW,CAAC,EACvB,OAAQ,KAAK,OAAO,8BAAgCwB,EAAIH,CAAM,EAAIA,CACtE,CACJ,CAAC,EACKI,EAAU,KAAK,OAAO,8BAAgCC,EAAIH,EAAO,KAAK,OAAO,EAAIA,EAAO,KAAK,QACnG,MAAO,CACH,QAAAE,EACA,YAAa,GAAGN,CAAW,GAAGM,CAAO,EACzC,CACJ,CACJ,CACJ,CAEA,iBAAiBzB,EAGd,CACC,IAAMoB,EAAY,IAAI3B,EAAU,IAAI,EACpC,OAAA2B,EAAU,OAAO,CACb,KAAM,aACN,MAAOpB,EAAO,QAAU,IAAM,MAC9B,UAAWD,GAAK,CACZ,IAAM0B,EAAU,KAAK,OAAO,8BAAgCC,EAAI3B,EAAE,OAAO,EAAIA,EAAE,QAC/EC,EAAO,UAAUyB,CAAO,CAC5B,EACA,OAAQzB,EAAO,SAAW,IAAM,MAChC,QAASA,EAAO,UAAY,IAAM,MAClC,KAAM,SAAW,CACb,IAAMiB,EAAQ,MAAM,KAAK,QAAQ,IAAI,EAE/BI,EADW,IAAIC,GAASL,EAAM,aAAa,EACzB,OAAO,CAC3B,UAAWA,EAAM,UACjB,SAAUjB,EAAO,QACrB,CAAC,EAAE,MAAM,EAAGiB,EAAM,UAAU,OAAS,GAAK,CAAC,EAC3C,MAAO,CACH,GAAIjB,EAAO,SAAW,CAAC,EACvB,OAAQ,KAAK,OAAO,8BAAgCwB,EAAIH,CAAM,EAAIA,EAClE,OAAQ,EACZ,CACJ,CACJ,CAAC,EACMD,EAAU,OAAO,CAC5B,CAEA,KAAKpB,EAOF,CACC,IAAMoB,EAAY,IAAI3B,EAAU,IAAI,EACpC,MAAO,CACH,GAAG2B,EAAU,OAAO,EACpB,IAAK,SAEC,CAcF,IAAMO,GAbS,MAAMP,EAAU,MAAM,CACjC,KAAM,sBACN,KAAM,CACF,GAAIpB,EAAO,SAAW,CAAC,EACvB,gBAAiBA,EAAO,gBACxB,SAAUA,EAAO,SAAS,IAAID,IACnB,CACH,KAAMA,EAAE,KACR,QAAS,KAAK,OAAO,8BAAgCyB,EAAIzB,EAAE,OAAO,EAAIA,EAAE,OAC5E,EACH,CACL,CACJ,CAAC,GACsB,KAAK,QAAQ,CAAC,EAAE,QAAQ,SAAW,GAC1D,MAAO,CACH,QAAS,KAAK,OAAO,8BAAgC2B,EAAIC,CAAO,EAAIA,CACxE,CACJ,CACJ,CACJ,CAEA,WAAW3B,EAGR,CACC,IAAMoB,EAAY,IAAI3B,EAAU,IAAI,EACpC,OAAA2B,EAAU,OAAO,CACb,KAAM,sBACN,MAAOpB,EAAO,QAAU,IAAM,MAC9B,UAAWD,GAAK,CACZ,IAAI4B,EAAU5B,EAAE,QAAQ,CAAC,EAAE,MAAM,QACjC,GAAI4B,EAAS,CACT,IAAMF,EAAU,KAAK,OAAO,8BAAgCC,EAAIC,CAAO,EAAIA,EAC3E3B,EAAO,UAAUyB,CAAO,CAC5B,CACJ,EACA,OAAQzB,EAAO,SAAW,IAAM,MAChC,QAASA,EAAO,UAAY,IAAM,MAClC,KAAM,CACF,GAAIA,EAAO,SAAW,CAAC,EACvB,OAAQ,GACR,SAAUA,EAAO,SAAS,IAAID,IACnB,CACH,KAAMA,EAAE,KACR,QAAS,KAAK,OAAO,8BAAgCyB,EAAIzB,EAAE,OAAO,EAAIA,EAAE,OAC5E,EACH,CACL,CACJ,CAAC,EACMqB,EAAU,OAAO,CAC5B,CACJ,EDpTO,IAAMQ,GAAN,MAAMC,CAAoB,CAA1B,cACHC,EAAA,cAASC,GAAM,OAAO,GAEtB,OAAO,gCAAgCC,EAIpC,CACC,MAAO,OAAMC,EAAiB,CAAE,OAAAC,EAAQ,SAAAC,CAAS,IAAW,CACxD,IAAMC,EAAS,IAAIP,EACbQ,EAAOD,EAAO,iBAAiB,EAC/BE,EAAS,OAAON,EAAO,QAAW,WAAa,MAAMA,EAAO,OAAO,EAAIA,EAAO,OACpFK,EAAK,UAAUC,CAAM,EACrB,IAAIC,EAAeC,EAAqBN,EAAO,MAAM,EACjDF,EAAO,OACPI,EAAO,SAASJ,EAAO,KAAK,EAE5BK,EAAK,OAAO,gCACZE,EAAe,KAAK,MAAME,EAAI,KAAK,UAAUF,CAAY,CAAC,CAAC,GAE/D,GAAM,CAAE,IAAAG,EAAK,OAAAC,CAAO,EAAIN,EAAK,KAAK,CAC9B,QAASL,EAAO,YAChB,SAAUC,EACV,gBAAiB,CACb,KAAM,cACN,OAAQM,CACZ,CACJ,CAAC,EACDJ,EAASQ,CAAM,EACf,GAAM,CAAE,QAAAC,CAAQ,EAAI,MAAMF,EAAI,EAC9B,OAAOL,EAAK,OAAO,8BAAgCQ,EAAID,CAAO,EAAIA,CACtE,CACJ,CAOA,SAASb,EAAsB,CAC3B,KAAK,OAASA,CAClB,CAOA,kBAAmB,CACf,OAAO,IAAIe,EAAmB,IAAI,CACtC,CACJ,EExDA,OAAS,QAAAC,OAAY,eAqCd,IAAMC,EAAN,MAAMC,CAAW,CAYpB,YAAYC,EAA2B,CAXvCC,EAAA,eACAA,EAAA,cAAiB,CACb,MAAO,yBACP,UAAW,KACX,YAAa,GACb,eAAgB,CACZ,QAAS,GACT,MAAO,4BACX,CACJ,GAGI,KAAK,OAASD,CAClB,CAOA,UAAUE,EAA0B,CAChC,OAAO,OAAO,KAAK,OAAQA,CAAO,CACtC,CAEA,OAAO,kBAAkBC,EAAmC,CACxD,GAAKA,EAGL,OAAOA,EAAO,UAAY,KACpB,OACA,CACE,gBAAiB,GACjB,cAAeA,EAAO,KAC1B,CACR,CAOA,MAAM,KAAKC,EAA4B,CAAC,EAAG,CACvC,IAAMC,EAAcC,GAAK,KAAKF,CAAQ,EAUhCG,GATW,MAAM,KAAK,OAAO,YAAY,OAAO,gBAAgB,CAClE,MAAO,KAAK,OAAO,MACnB,SAAUF,EACV,OAAQ,CACJ,YAAa,KAAK,OAAO,YACzB,gBAAiB,KAAK,OAAO,UAC7B,eAAgBN,EAAW,kBAAkB,KAAK,OAAO,cAAc,CAC3E,CACJ,CAAC,GACqB,KACtB,MAAO,CACH,KAAAQ,EACA,YAAa,CACT,GAAGF,EACH,CACI,KAAM,QACN,MAAO,CACH,CACI,KAAAE,CACJ,CACJ,CACJ,CACJ,CACJ,CACJ,CAOA,WAAWC,EAMR,CACC,IAAMC,EAAQ,CACV,WAAY,IAAI,eACpB,EAWA,OAVc,KAAK,OAAO,YAAY,OAAO,sBAAsB,CAC/D,MAAO,KAAK,OAAO,MACnB,SAAUD,EAAO,SACjB,OAAQ,CACJ,YAAaC,EAAM,WAAW,OAC9B,YAAa,KAAK,OAAO,YACzB,gBAAiB,KAAK,OAAO,UAC7B,eAAgBV,EAAW,kBAAkB,KAAK,OAAO,cAAc,CAC3E,CACJ,CAAC,EACK,KAAK,MAAMW,GAAW,CACxB,GAAI,CACA,cAAiBC,KAASD,EAAQ,CAC9B,IAAME,EAAQD,EAAM,aAAa,CAAC,EAAE,SAAS,OAAS,CAAC,EACvD,QAASE,KAAQD,EACTC,EAAK,OACDA,EAAK,QACLL,EAAO,aAAaK,EAAK,IAAI,EAE7BL,EAAO,UAAUK,EAAK,IAAI,EAI1C,CACAL,EAAO,MAAM,CACjB,OAASM,EAAO,CACZ,GAAIL,EAAM,WAAW,OAAO,QACxBD,EAAO,MAAM,MAEb,OAAMM,CAEd,CACJ,CAAC,EACI,MAAOA,GAAU,CACdN,EAAO,QAAQM,CAAK,CACxB,CAAC,EACE,CACH,OAAQ,IAAM,CACVL,EAAM,WAAW,MAAM,CAC3B,CACJ,CACJ,CACJ,EC5JO,IAAMM,EAAN,KAA6B,CAQhC,YAAYC,EAA2B,CAPvCC,EAAA,KAAQ,UACRA,EAAA,KAAQ,SAAiB,CACrB,MAAO,0BACP,KAAM,KACN,YAAa,KACjB,GAGI,KAAK,OAASD,CAClB,CAOA,UAAUE,EAA0B,CAChC,OAAO,OAAO,KAAK,OAAQA,CAAO,CACtC,CAOA,MAAM,OAAOC,EAAgB,CAUzB,MAAO,CACH,QAVa,MAAM,KAAK,OAAO,YAAY,OAAO,eAAe,CACjE,MAAO,KAAK,OAAO,MACnB,OAAAA,EACA,OAAQ,CACJ,eAAgB,EAChB,YAAa,KAAK,OAAO,YACzB,UAAW,KAAK,OAAO,IAC3B,CACJ,CAAC,GAEoB,iBAAiB,IAAIC,IAC3B,CACH,IAAKA,EAAE,OAAO,YAAc,GAC5B,SAAUA,EAAE,OAAO,UAAY,EACnC,EACH,GAAK,CAAC,CACX,CACJ,CACJ,EClCO,IAAMC,GAAN,MAAMC,CAAkB,CAG3B,YAAYC,EAAkB,CAF9BC,EAAA,oBAGI,KAAK,YAAcD,CACvB,CAEA,OAAO,kCAAkCE,EAAyC,CAC9E,IAAMC,EAAkBC,GAChB,OAAOA,GAAY,SACZ,CACH,CACI,KAAMA,CACV,CACJ,EACO,MAAM,QAAQA,CAAO,EACrBA,EAAQ,IAAI,CAAC,CAAE,KAAAC,EAAM,UAAAC,EAAW,KAAAC,CAAK,IAAsC,CAC9E,GAAIF,IAAS,YAAa,CAEtB,IAAMG,EAAMF,GAAW,KAAO,GACxBG,EAAWD,EAAI,SAAS,gBAAgB,EAAI,YAAc,aAChE,MAAO,CACH,WAAY,CACR,KAAMA,EAAI,MAAM,SAAS,EAAE,CAAC,GAAK,GACjC,SAAAC,CACJ,CACJ,CACJ,KACI,OAAO,CACH,KAAMF,GAAQ,EAClB,CAER,CAAC,EAEE,CAAC,EAEZ,OAAOL,EAAS,IAAKQ,GACbA,EAAQ,OAAS,QAAUA,EAAQ,OAAS,SACrC,CACH,KAAM,OACN,MAAOP,EAAeO,EAAQ,OAAO,CACzC,EAEO,CACH,KAAM,QACN,MAAOP,EAAeO,EAAQ,OAAO,CACzC,CAEP,CACL,CAEA,OAAO,gCAAgCC,EAIpC,CACC,IAAMX,EAA2BW,EAAO,YAClCC,EAA8BC,IAC5BA,EAAO,OAAS,UAChB,OAAOA,EAAO,qBACd,OAAO,KAAKA,EAAO,UAAU,EAAE,QAASC,GAAQ,CAC5CF,EAA2BC,EAAO,WAAWC,CAAG,CAAC,CACrD,CAAC,GACMD,EAAO,OAAS,SACvBD,EAA2BC,EAAO,KAAK,EAEpCA,GAEX,MAAO,OAAOX,EAAiB,CAAE,OAAAW,EAAQ,gBAAAE,CAAgB,IAAW,CAChE,IAAMC,EAAS,OAAOL,EAAO,QAAW,WAAa,MAAMA,EAAO,OAAO,EAAIA,EAAO,OAapF,OAZiB,MAAMX,EAAY,OAAO,gBAAgB,CACtD,MAAOW,EAAO,MACd,SAAUZ,EAAkB,kCAAkCG,CAAQ,EACtE,OAAQ,CACJ,YAAaa,EAAgB,OAC7B,gBAAiBC,EAAO,UACxB,YAAaA,EAAO,YACpB,iBAAkB,mBAClB,mBAAoBC,EAAqBJ,EAAO,MAAM,EACtD,eAAgBK,EAAW,kBAAkBF,EAAO,cAAc,CACtE,CACJ,CAAC,GACe,MAAQ,EAC5B,CACJ,CAEA,YAAa,CACT,OAAO,IAAIE,EAAW,IAAI,CAC9B,CAEA,wBAAyB,CACrB,OAAO,IAAIC,EAAuB,IAAI,CAC1C,CACJ,EC5FO,IAAMC,EAAN,KAAiC,CAEpC,YAAYC,EAAsB,CADlCC,EAAA,KAAQ,UAEJ,KAAK,OAASD,CAClB,CAMQ,kBAAkBE,EAAiB,CACvC,MAAO,CACH,OAAQA,EAAS,KAAKC,GAAKA,EAAE,OAAS,QAAQ,GAAG,QACjD,SAAUD,EAAS,OAAOC,GAAKA,EAAE,OAAS,QAAQ,CACtD,CACJ,CAEA,mBAAoB,CAChB,IAAMH,EAAS,KAAK,OAAO,EACrBI,EAAe,KAAK,MAAMJ,EAAO,UAAY,GAAI,EACvD,OAAOA,EAAO,WAAa,GACrB,OACA,CACE,cAAeI,GAAgB,KAAO,KAAQA,EAAe,KAAQ,KAAQA,EAC7E,KAAM,SACV,CACR,CAEA,2BAA2BF,EAAqBG,EAAoE,CAChH,IAAML,EAAS,KAAK,OAAO,EACrBM,EAAoB,KAAK,kBAAkBJ,CAAQ,EACzD,MAAO,CACH,MAAOF,EAAO,MACd,WAAYA,EAAO,UACnB,YAAaA,EAAO,YACpB,OAAQM,EAAkB,OAC1B,SAAUA,EAAkB,SAC5B,MAAO,CACH,CACI,KAAM,OACN,YAAa,gBACb,aAAcD,CAClB,CACJ,EACA,YAAa,CACT,KAAM,OACN,KAAM,MACV,CACJ,CACJ,CAEA,4BAA4BE,EAAyE,CAEjG,IAAIC,GADsB,YAAaD,EAASA,EAAO,QAAQ,KAAKJ,GAAKA,EAAE,OAAS,UAAU,EAAI,OACnE,OAAS,KACxC,OAAIK,GAAY,KACL,OAEJ,KAAK,UAAUA,CAAQ,CAClC,CAEA,eAAeN,EAAwE,CACnF,IAAMF,EAAS,KAAK,OAAO,EACrBS,EAAc,KAAK,kBAAkBP,CAAQ,EACnD,MAAO,CACH,MAAOF,EAAO,MACd,WAAYA,EAAO,UACnB,YAAaA,EAAO,SAAW,EAAIA,EAAO,YAC1C,OAAQS,EAAY,OACpB,SAAUA,EAAY,SACtB,SAAU,KAAK,kBAAkB,CACrC,CACJ,CAEA,gBAAgBF,EAAyE,CACrF,IAAIG,EAAmB,CAAC,EACxB,GAAI,YAAaH,EACb,QAASI,KAAgBJ,EAAO,QACxBI,EAAa,OAAS,QACtBD,EAAO,KAAKC,EAAa,IAAI,EAIzC,OAAOD,EAAO,KAAK;AAAA,CAAI,CAC3B,CAEA,sBAAsBH,EAA2E,CAC7F,IAAIG,EAAmB,CAAC,EACxB,GAAI,YAAaH,EACb,QAASI,KAAgBJ,EAAO,QACxBI,EAAa,OAAS,YACtBD,EAAO,KAAKC,EAAa,QAAQ,EAI7C,OAAOD,CACX,CAEA,qBAAqBR,EAAwE,CACzF,IAAMF,EAAS,KAAK,OAAO,EACrBS,EAAc,KAAK,kBAAkBP,CAAQ,EACnD,MAAO,CACH,MAAOF,EAAO,MACd,WAAYA,EAAO,UACnB,YAAaA,EAAO,SAAW,EAAIA,EAAO,YAC1C,OAAQS,EAAY,OACpB,OAAQ,GACR,SAAU,KAAK,kBAAkB,EACjC,SAAUA,EAAY,QAC1B,CACJ,CACJ,EAEaG,EAAN,KAAoB,CAUvB,YAAYC,EAAiC,CAT7CZ,EAAA,kBACAA,EAAA,qBAAgB,IAAIF,EAA2B,IAAM,KAAK,MAAM,GAChEE,EAAA,cAAiB,CACb,MAAO,0BACP,SAAU,GACV,UAAW,KACX,YAAa,EACjB,GAGI,KAAK,UAAYY,CACrB,CAOA,UAAUC,EAA0B,CAChC,OAAO,OAAO,KAAK,OAAQA,CAAO,CACtC,CAOA,MAAM,iBAAiBZ,EAAqBG,EAAiBS,EAAiD,CAC1G,IAAMD,EAAY,KAAK,UAAU,aAC3BE,EAAO,KAAK,cAAc,2BAA2Bb,EAAUG,CAAU,EACzEW,EAAM,MAAMH,EAAU,SAAS,OAAOE,EAAM,CAC9C,OAAQD,GAAS,iBAAiB,MACtC,CAAC,EACD,OAAO,KAAK,cAAc,4BAA4BE,CAAG,CAC7D,CAEA,MAAM,4BAA4Bd,EAAqBG,EAAiBS,EAAiD,CACrH,IAAMD,EAAY,KAAK,UAAU,aAC3BE,EAAO,KAAK,cAAc,2BAA2Bb,EAAUG,CAAU,EACzEW,EAAM,MAAMH,EAAU,SAAS,OAAOE,EAAM,CAC9C,OAAQD,GAAS,iBAAiB,MACtC,CAAC,EACD,MAAO,CACH,KAAM,KAAK,cAAc,4BAA4BE,CAAG,EACxD,SAAU,KAAK,cAAc,sBAAsBA,CAAG,CAC1D,CACJ,CAOA,MAAM,KAAKd,EAAsB,CAAC,EAAG,CACjC,IAAMW,EAAY,KAAK,UAAU,aAC3BE,EAAO,KAAK,cAAc,eAAeb,CAAQ,EACjDc,EAAM,MAAMH,EAAU,SAAS,OAAOE,CAAI,EAChD,OAAO,KAAK,cAAc,gBAAgBC,CAAG,CACjD,CAOA,MAAM,eAAed,EAAsB,CAAC,EAAG,CAC3C,IAAMW,EAAY,KAAK,UAAU,aAC3BE,EAAO,KAAK,cAAc,eAAeb,CAAQ,EACjDc,EAAM,MAAMH,EAAU,SAAS,OAAOE,CAAI,EAChD,MAAO,CACH,KAAM,KAAK,cAAc,gBAAgBC,CAAG,EAC5C,SAAU,KAAK,cAAc,sBAAsBA,CAAG,CAC1D,CACJ,CAOA,WAAWC,EAMR,CACC,IAAIC,EAAqG,KACnGL,EAAY,KAAK,UAAU,aAC3B,CAAE,WAAAM,EAAY,UAAAC,EAAW,MAAAC,EAAO,QAAAC,CAAQ,EAAIL,EAC5CF,EAAO,KAAK,cAAc,qBAAqBE,EAAO,QAAQ,EAsBpE,OArB4B,SAAY,CACpC,GAAI,CACA,IAAIV,EAAS,MAAMM,EAAU,SAAS,OAAOE,CAAI,EACjD,GAAIR,GAAU,MAAQ,eAAgBA,EAAQ,CAC1CW,EAASX,EACT,cAAiBgB,KAAiBL,EAC1BK,EAAc,OAAS,wBACnBA,EAAc,MAAM,OAAS,kBAAoBJ,GACjDA,EAAWI,EAAc,MAAM,QAAQ,EAEvCA,EAAc,MAAM,OAAS,cAC7BH,EAAUG,EAAc,MAAM,IAAI,EAIlD,CACAF,EAAM,CACV,OAASG,EAAO,CACZF,EAAQE,CAAK,CACjB,CACJ,GACoB,EACb,CACH,OAAQ,IAAM,CACV,IAAMC,EAAM,YAAY,IAAM,CACtBP,GAAUA,EAAO,aACjBA,EAAO,WAAW,MAAM,EACxB,cAAcO,CAAG,EAEzB,EAAG,EAAE,CACT,CACJ,CACJ,CACJ,EC/OO,IAAMC,GAAN,MAAMC,CAAqB,CAG9B,YAAYC,EAAmB,CAF/BC,EAAA,qBAGI,KAAK,aAAeD,CACxB,CAEA,OAAO,qCAAqCE,EAA+B,CAyBvE,OAxBmBA,EAAS,IAAIC,IACrB,CACH,KAAMA,EAAE,KACR,QAAS,OAAOA,EAAE,SAAY,SACxBA,EAAE,QACFA,EAAE,QAAQ,IAAKC,GAAY,CACzB,GAAIA,EAAQ,OAAS,YAAa,CAC9B,IAAMC,EAAMD,EAAQ,WAAW,KAAO,GACtC,MAAO,CACH,KAAM,QACN,OAAQ,CACJ,KAAM,SACN,WAAYC,EAAI,MAAM,CAAC,EAAE,MAAM,GAAG,EAAE,CAAC,EACrC,KAAMA,EAAI,MAAM,GAAG,EAAE,CAAC,CAC1B,CACJ,CACJ,CACA,MAAO,CACH,KAAM,OACN,KAAMD,EAAQ,IAClB,CACJ,CAAC,CACT,EACH,CAEL,CAEA,OAAO,gCAAgCE,EAGpC,CAEC,IAAMC,EADY,IAAIR,EAAqBO,EAAO,YAAY,EACvC,WAAW,EAClC,OAAAC,EAAK,UAAUD,EAAO,QAAU,CAAC,CAAC,EAC3B,MAAOJ,EAAiB,CAAE,OAAAM,EAAQ,gBAAAC,CAAgB,IAAW,CAChE,IAAMC,EAAaC,EAAqBH,EAAO,MAAM,EAIrD,OAHgB,MAAMD,EAAK,iBAAiBL,EAAUQ,EAAY,CAC9D,gBAAAD,CACJ,CAAC,CAEL,CACJ,CAEA,YAAa,CACT,OAAO,IAAIG,EAAc,IAAI,CACjC,CACJ,ECxEA,OAAOC,OAAW,QCAlB,OAAS,QAAAC,OAAY,eAwLd,IAAMC,EAAN,KAAY,CAQf,YAAYC,EAAmB,CAP/BC,EAAA,YACAA,EAAA,cAAiB,CACb,MAAO,8BACP,YAAa,EACb,UAAW,MACf,GAGI,KAAK,IAAMD,CACf,CAOA,UAAUE,EAA0B,CAChC,OAAO,OAAO,KAAK,OAAQA,CAAO,CACtC,CAOA,MAAM,KAAKC,EAAuB,CAAC,EAAGD,EAInC,CACC,IAAME,EAAcC,GAAK,KAAKF,CAAQ,EAClCG,EACAJ,GAAS,aACTI,EAAkB,CACd,KAAM,cACN,OAAQJ,EAAQ,WAAW,MAC/B,GAEJ,IAAMK,EAAS,MAAM,KAAK,IAAI,OAAO,KAAkB,gCAAiC,CACpF,MAAO,KAAK,OAAO,MACnB,MAAOH,EACP,YAAa,KAAK,OAAO,YACzB,kBAAmB,KAAK,OAAO,UAC/B,UAAW,KAAK,OAAO,UACvB,KAAME,GAAmB,KACnB,OACA,CACE,OAAQ,CACJ,GAAGA,EACH,KAAM,iBACV,CACJ,CACR,EAAG,CACC,OAAQJ,GAAS,iBAAiB,OAClC,QAAS,CACL,eAAgB,mBAChB,cAAiB,UAAU,KAAK,IAAI,OAAO,EAC/C,CACJ,CAAC,EACKM,EAAaD,EAAO,KAAK,OAAO,KAAKE,GAAKA,EAAE,OAAS,SAAS,GAAG,SAAS,KAAKA,GAAKA,EAAE,OAAS,aAAa,EAC5GC,EAAgBH,EAAO,KAAK,OAAO,KAAKE,GAAKA,EAAE,OAAS,WAAW,GAAG,SAAS,KAAKA,GAAKA,EAAE,OAAS,cAAc,EAClHE,EAAU,CACZ,KAAM,YACN,QAASH,GAAY,MAAQ,EACjC,EACA,OAAAJ,EAAY,KAAKO,CAAO,EACjB,CACH,GAAIJ,GAAQ,KAAK,GACjB,KAAMI,EAAQ,QACd,YAAAP,EACA,cAAeM,GAAe,KAC9B,YAAaH,EAAO,IACxB,CACJ,CAEA,WAAWK,EAOR,CACC,IAAMC,EAAa,IAAI,gBACvB,aAAM,gCAAiC,CACnC,OAAQ,OACR,QAAS,CACL,eAAgB,mBAChB,cAAiB,UAAU,KAAK,IAAI,OAAO,EAC/C,EACA,KAAM,KAAK,UAAU,CACjB,MAAO,KAAK,OAAO,MACnB,OAAQ,GACR,MAAOD,EAAO,SACd,kBAAmB,KAAK,OAAO,UAC/B,UAAW,KAAK,OAAO,SAC3B,CAAC,EACD,OAAQC,EAAW,MACvB,CAAC,EAAE,KAAK,MAAMC,GAAY,CACtB,GAAIA,EAAS,KAAO,GAChB,MAAM,IAAI,MAAM,uBAAuBA,EAAS,MAAM,EAAE,EAE5D,IAAIC,EAAY,GACVC,EAASF,EAAS,MAAM,YAAY,IAAI,iBAAmB,EAAE,UAAU,EAC7E,GAAI,CAACE,EACD,MAAM,IAAI,MAAM,oBAAoB,EAExC,OAAa,CACT,GAAM,CAAE,MAAAC,EAAO,KAAAC,CAAK,EAAI,MAAMF,EAAO,KAAK,EAC1C,GAAIE,EACA,MAEJ,IAAIC,EAAWF,EAAM,MAAM;AAAA,CAAI,EAAE,OAAOG,GAAKA,EAAE,WAAW,OAAO,CAAC,EAClE,QAASC,KAAQF,EAAU,CACvB,IAAML,EAAWQ,EAAgCP,EAAYM,EAAK,MAAM,CAAC,CAAC,EAC1E,QAAWE,KAAQT,EAAS,MACpBS,EAAK,OAAS,yCACdX,EAAO,YAAcA,EAAO,WAAWW,EAAK,OAAS,EAAE,EAEvDA,EAAK,OAAS,8BACdX,EAAO,UAAUW,EAAK,OAAS,EAAE,EAEjCA,EAAK,OAAS,sBACdX,EAAO,MAAM,EAGrBG,EAAYD,EAAS,SACzB,CACJ,CACJ,CAAC,EAAE,MAAMU,GAAS,CACVA,EAAM,OAAS,aACfZ,EAAO,MAAM,EAEbA,EAAO,QAAQY,CAAK,CAE5B,CAAC,EACM,CACH,OAAQ,IAAMX,EAAW,MAAM,CACnC,CACJ,CAMA,MAAM,SAASY,EAA2BC,EAA0B,CAAC,EAAG,CACpE,IAAMnB,EAAS,MAAM,KAAK,KAAK,CAC3B,GAAGmB,EACH,CACI,KAAM,OACN,QAAS,MAAM,QAAQD,CAAM,EAAIA,EAAO,KAAK;AAAA,CAAI,EAAIA,CACzD,CACJ,CAAC,EACD,MAAO,CACH,OAAAlB,EACA,SAAWkB,GAA8B,KAAK,SAASA,EAAQlB,EAAO,WAAW,CACrF,CACJ,CACJ,ECtUO,IAAMoB,EAAN,KAAwB,CAM3B,YAAYC,EAAmB,CAL/BC,EAAA,KAAQ,OACRA,EAAA,KAAQ,SAAiB,CACrB,MAAO,cACX,GAGI,KAAK,IAAMD,CACf,CAOA,UAAUE,EAA0B,CAChC,OAAO,OAAO,KAAK,OAAQA,CAAO,CACtC,CAOA,MAAM,OAAOC,EAAgB,CAazB,OAZe,MAAM,KAAK,IAAI,OAAO,KAAkB,yCAA0C,CAC7F,OAAAA,EACA,EAAG,EACH,MAAO,KAAK,OAAO,MACnB,gBAAiB,UACrB,EAAG,CACC,QAAS,IACT,QAAS,CACL,eAAgB,mBAChB,cAAiB,UAAU,KAAK,IAAI,OAAO,EAC/C,CACJ,CAAC,GACa,IAClB,CACJ,EFnDO,IAAMC,GAAN,MAAMC,CAAa,CAsDtB,YAAYC,EAAS,GAAI,CArDzBC,EAAA,cAASC,GAAM,OAAO,GACtBD,EAAA,eAAU,IAqDN,KAAK,QAAUD,CACnB,CApDA,OAAO,kBACHA,EACAG,EAA6D,CAAC,EAC9DC,EAGF,CACE,MAAO,OAAMC,EAAiB,CAAE,SAAAC,CAAS,IAAW,CAChD,IAAMC,EAAM,IAAIR,EAAa,OAAOC,GAAW,SAAWA,EAAS,MAAMA,EAAO,CAAC,EAC3EQ,EAAOD,EAAI,WAAW,EACtBE,EAAkB,IAAI,gBACxBL,GAAWA,EAAQ,OACnBG,EAAI,SAASH,EAAQ,KAAK,EAE9BI,EAAK,UAAU,OAAOL,GAAW,WAAa,MAAMA,EAAO,EAAIA,CAAM,EACrEG,EAAS,IAAMG,EAAgB,MAAM,CAAC,EACtC,GAAM,CAAE,KAAAC,CAAK,EAAI,MAAMF,EAAK,KAAKH,EAAU,CACvC,gBAAAI,CACJ,CAAC,EACD,OAAOC,CACX,CACJ,CAEA,OAAO,gCAAgCC,EAIpC,CACC,MAAO,OAAMN,EAAiB,CAAE,OAAAO,EAAQ,gBAAAH,CAAgB,IAAW,CAC/D,IAAMF,EAAM,IAAIR,EAAa,OAAOY,EAAO,QAAW,SAAWA,EAAO,OAAS,MAAMA,EAAO,OAAO,CAAC,EAChGH,EAAOD,EAAI,WAAW,EACxBI,EAAO,QACPH,EAAK,UAAU,OAAOG,EAAO,QAAW,WAAa,MAAMA,EAAO,OAAO,EAAIA,EAAO,MAAM,EAE1FA,EAAO,OACPJ,EAAI,SAASI,EAAO,KAAK,EAE7B,IAAME,EAAaC,EAAqBF,EAAO,MAAM,EAC/C,CAAE,KAAAF,CAAK,EAAI,MAAMF,EAAK,KAAKH,EAAU,CACvC,gBAAAI,EACA,WAAY,CACR,KAAM,OACN,OAAQ,GACR,OAAQI,CACZ,CACJ,CAAC,EACD,OAAOH,CACX,CACJ,CAWA,SAASR,EAAY,CACjB,KAAK,OAASA,CAClB,CAOA,iBAAiBF,EAAgB,CAC7B,KAAK,QAAUA,CACnB,CAEA,YAAa,CACT,OAAO,IAAIe,EAAM,IAAI,CACzB,CAEA,wBAAyB,CACrB,OAAO,IAAIC,EAAkB,IAAI,CACrC,CACJ",
  "names": ["plugins_exports", "__export", "LimiterPlugin", "LimiterPluginGlobState", "PrintLogPlugin", "RetryPlugin", "RolePlugin", "Event", "ChatBrokerPlugin", "params", "__publicField", "Event", "data", "callback", "retry_default", "ChatBrokerPlugin", "z", "log", "attach", "params", "count", "retry", "messages", "changeMessages", "print_log_default", "ChatBrokerPlugin", "z", "params", "log", "attach", "lastUserMessage", "messages", "parseText", "output", "Event", "flow", "Schedule", "config", "state", "limiter_default", "ChatBrokerPlugin", "attach", "now", "time", "nextId", "uid", "resolve", "id", "off", "role_default", "ChatBrokerPlugin", "z", "attach", "params", "messages", "changeMessages", "PrintLogPlugin", "print_log_default", "RetryPlugin", "retry_default", "LimiterPlugin", "limiter_default", "LimiterPluginGlobState", "RolePlugin", "role_default", "templates_exports", "__export", "requireJsonResponse", "requireJsonResponseWithHandlebars", "requireJsonResponseWithJsonSchema", "Handlebars", "record", "question", "format", "key", "value", "handlebars", "chinese_conv_exports", "__export", "s2t", "t2s", "Converter", "text", "JSON5", "TextParser", "_TextParser", "params", "__publicField", "text", "jsonRegex", "matchedText", "JSON5", "Event", "flow", "Hook", "Log", "z", "toJSONSchema", "validate", "target", "schemaCallback", "z", "validateToJsonSchema", "schema", "toJSONSchema", "ParserError", "error", "parserFails", "__publicField", "Translator", "params", "__publicField", "data", "context", "scheme", "validate", "prompt", "schema", "text", "result", "parserName", "parserFails", "parse", "error", "ParserError", "z", "ChatBroker", "params", "__publicField", "Hook", "Event", "Log", "Translator", "TextParser", "context", "key", "requestId", "data", "id", "flow", "waitCancel", "isCancel", "isSending", "abortController", "listeners", "cancelTrigger", "eventOff", "e", "onCancel", "cb", "request", "schema", "output", "plugins", "metadata", "question", "preMessages", "messages", "ms", "count", "doBreak", "response", "parseText", "retryFlag", "lastUserMessage", "sender", "error", "ParserError", "text", "z", "validateToJsonSchema", "z", "CtoD", "params", "__publicField", "install", "ChatBroker", "context", "id", "plugins", "data", "metadata", "changeMessages", "changeOutputSchema", "schema", "z", "messages", "e", "parseJSONStream", "data", "items", "buffer", "depth", "inString", "escapeNext", "objectStarted", "i", "char", "trimmed", "axios", "OpenAIVision", "openai", "__publicField", "options", "messages", "result", "message", "json", "OpenAIChat", "openai", "__publicField", "options", "input", "result", "messages", "newMessages", "json", "response_format", "outputText", "e", "reasoningText", "message", "params", "controller", "response", "lastChunk", "reader", "value", "done", "dataList", "v", "data", "parseJSONStream", "item", "error", "prompt", "oldMessages", "OpenAIImagesGeneration", "openai", "__publicField", "options", "prompt", "OpenAICtodService", "_OpenAICtodService", "apiKey", "__publicField", "axios", "config", "options", "messages", "abortController", "openai", "chat", "text", "params", "schema", "onCancel", "jsonSchema", "validateToJsonSchema", "baseUrl", "OpenAIChat", "OpenAIVision", "OpenAIImagesGeneration", "axios", "flow", "Once", "Template", "Requester", "core", "__publicField", "streamAbortController", "streamAbortControllerId", "flow", "e", "params", "signal", "controllerId", "end", "reader", "response", "done", "chunk", "value", "readerDone", "payloads", "payload", "data", "error", "LlamaCppCompletion", "Once", "url", "props", "config", "lastMessage", "requester", "prompt", "Template", "result", "t2s", "message", "s2t", "content", "LlamaCppCtodService", "_LlamaCppCtodService", "__publicField", "axios", "params", "messages", "schema", "onCancel", "ll3cpp", "chat", "config", "formatSchema", "validateToJsonSchema", "t2s", "run", "cancel", "message", "s2t", "LlamaCppCompletion", "json", "GoogleChat", "_GoogleChat", "google", "__publicField", "options", "config", "messages", "newMessages", "json", "text", "params", "state", "stream", "chunk", "parts", "part", "error", "GoogleImagesGeneration", "google", "__publicField", "options", "prompt", "e", "GoogleCtodService", "_GoogleCtodService", "googleGenAI", "__publicField", "messages", "contentToParts", "content", "type", "image_url", "text", "url", "mimeType", "message", "params", "removeAdditionalProperties", "schema", "key", "abortController", "config", "validateToJsonSchema", "GoogleChat", "GoogleImagesGeneration", "AnthropicChatDataGenerator", "config", "__publicField", "messages", "e", "budgetTokens", "jsonSchema", "translateMessages", "result", "response", "newMessages", "output", "contentBlock", "AnthropicChat", "anthropic", "options", "body", "msg", "params", "stream", "onThinking", "onMessage", "onEnd", "onError", "messageStream", "error", "int", "AnthropicCtodService", "_AnthropicCtodService", "anthropicSdk", "__publicField", "messages", "e", "content", "url", "params", "chat", "schema", "abortController", "jsonSchema", "validateToJsonSchema", "AnthropicChat", "axios", "json", "XChat", "xAi", "__publicField", "options", "messages", "newMessages", "json", "response_format", "result", "outputText", "e", "reasoningText", "message", "params", "controller", "response", "lastChunk", "reader", "value", "done", "dataList", "v", "data", "parseJSONStream", "item", "error", "prompt", "oldMessages", "XImagesGeneration", "xAi", "__publicField", "options", "prompt", "XCtodService", "_XCtodService", "apiKey", "__publicField", "axios", "config", "options", "messages", "onCancel", "xAi", "chat", "abortController", "text", "params", "schema", "jsonSchema", "validateToJsonSchema", "XChat", "XImagesGeneration"]
}
